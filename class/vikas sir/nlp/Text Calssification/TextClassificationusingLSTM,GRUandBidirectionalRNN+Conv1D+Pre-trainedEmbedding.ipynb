{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e42f4647",
   "metadata": {},
   "source": [
    "### Import the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f60205b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f6984c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#RockyFire Update =&gt; California Hwy. 20 closed...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#flood #disaster Heavy rain causes flash flood...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'm on top of the hill and I can see a fire in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>There's an emergency evacuation happening now ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'm afraid that the tornado is coming to our a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Three people died from the heat wave so far</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Haha South Tampa is getting flooded hah- WAIT ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#raining #flooding #Florida #TampaBay #Tampa 1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#Flood in Bago Myanmar #We arrived Bago</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Damage to school bus on 80 in multi car crash ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What's up man?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I love fruits</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Summer is lovely</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My car is so fast</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What a goooooooaaaaaal!!!!!!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>this is ridiculous....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>London is cool ;)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Love skiing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What a wonderful day!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LOOOOOOL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No way...I can't eat that shit</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Was in NYC last week!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Love my girlfriend</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cooool :)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Do you like pasta?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The end!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>48</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>@bbcmtd Wholesale Markets ablaze http://t.co/l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>49</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Est. September 2012 - Bristol</td>\n",
       "      <td>We always try to bring the heavy. #metal #RT h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>50</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>AFRICA</td>\n",
       "      <td>#AFRICANBAZE: Breaking news:Nigeria flag set a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>52</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Philadelphia, PA</td>\n",
       "      <td>Crying out for more! Set me ablaze</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>53</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>London, UK</td>\n",
       "      <td>On plus side LOOK AT THE SKY LAST NIGHT IT WAS...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>54</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Pretoria</td>\n",
       "      <td>@PhDSquares #mufc they've built so much hype a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>55</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>World Wide!!</td>\n",
       "      <td>INEC Office in Abia Set Ablaze - http://t.co/3...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>56</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Barbados #Bridgetown JAMAICA ÛÒ Two cars set ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>57</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Paranaque City</td>\n",
       "      <td>Ablaze for you Lord :D</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>59</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Live On Webcam</td>\n",
       "      <td>Check these out: http://t.co/rOI2NSmEJJ http:/...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>61</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>NaN</td>\n",
       "      <td>on the outside you're ablaze and alive\\nbut yo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>62</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>milky way</td>\n",
       "      <td>Had an awesome time visiting the CFC head offi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>63</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SOOOO PUMPED FOR ABLAZE ???? @southridgelife</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>64</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I wanted to set Chicago ablaze with my preachi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>65</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I gained 3 followers in the last week. You? Kn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>66</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>GREENSBORO,NORTH CAROLINA</td>\n",
       "      <td>How the West was burned: Thousands of wildfire...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>67</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Building the perfect tracklist to life leave t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>68</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Live On Webcam</td>\n",
       "      <td>Check these out: http://t.co/rOI2NSmEJJ http:/...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>71</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>England.</td>\n",
       "      <td>First night with retainers in. It's quite weir...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id keyword                       location  \\\n",
       "0    1     NaN                            NaN   \n",
       "1    4     NaN                            NaN   \n",
       "2    5     NaN                            NaN   \n",
       "3    6     NaN                            NaN   \n",
       "4    7     NaN                            NaN   \n",
       "5    8     NaN                            NaN   \n",
       "6   10     NaN                            NaN   \n",
       "7   13     NaN                            NaN   \n",
       "8   14     NaN                            NaN   \n",
       "9   15     NaN                            NaN   \n",
       "10  16     NaN                            NaN   \n",
       "11  17     NaN                            NaN   \n",
       "12  18     NaN                            NaN   \n",
       "13  19     NaN                            NaN   \n",
       "14  20     NaN                            NaN   \n",
       "15  23     NaN                            NaN   \n",
       "16  24     NaN                            NaN   \n",
       "17  25     NaN                            NaN   \n",
       "18  26     NaN                            NaN   \n",
       "19  28     NaN                            NaN   \n",
       "20  31     NaN                            NaN   \n",
       "21  32     NaN                            NaN   \n",
       "22  33     NaN                            NaN   \n",
       "23  34     NaN                            NaN   \n",
       "24  36     NaN                            NaN   \n",
       "25  37     NaN                            NaN   \n",
       "26  38     NaN                            NaN   \n",
       "27  39     NaN                            NaN   \n",
       "28  40     NaN                            NaN   \n",
       "29  41     NaN                            NaN   \n",
       "30  44     NaN                            NaN   \n",
       "31  48  ablaze                     Birmingham   \n",
       "32  49  ablaze  Est. September 2012 - Bristol   \n",
       "33  50  ablaze                         AFRICA   \n",
       "34  52  ablaze               Philadelphia, PA   \n",
       "35  53  ablaze                     London, UK   \n",
       "36  54  ablaze                       Pretoria   \n",
       "37  55  ablaze                   World Wide!!   \n",
       "38  56  ablaze                            NaN   \n",
       "39  57  ablaze                 Paranaque City   \n",
       "40  59  ablaze                 Live On Webcam   \n",
       "41  61  ablaze                            NaN   \n",
       "42  62  ablaze                      milky way   \n",
       "43  63  ablaze                            NaN   \n",
       "44  64  ablaze                            NaN   \n",
       "45  65  ablaze                            NaN   \n",
       "46  66  ablaze      GREENSBORO,NORTH CAROLINA   \n",
       "47  67  ablaze                            NaN   \n",
       "48  68  ablaze                 Live On Webcam   \n",
       "49  71  ablaze                       England.   \n",
       "\n",
       "                                                 text  target  \n",
       "0   Our Deeds are the Reason of this #earthquake M...       1  \n",
       "1              Forest fire near La Ronge Sask. Canada       1  \n",
       "2   All residents asked to 'shelter in place' are ...       1  \n",
       "3   13,000 people receive #wildfires evacuation or...       1  \n",
       "4   Just got sent this photo from Ruby #Alaska as ...       1  \n",
       "5   #RockyFire Update => California Hwy. 20 closed...       1  \n",
       "6   #flood #disaster Heavy rain causes flash flood...       1  \n",
       "7   I'm on top of the hill and I can see a fire in...       1  \n",
       "8   There's an emergency evacuation happening now ...       1  \n",
       "9   I'm afraid that the tornado is coming to our a...       1  \n",
       "10        Three people died from the heat wave so far       1  \n",
       "11  Haha South Tampa is getting flooded hah- WAIT ...       1  \n",
       "12  #raining #flooding #Florida #TampaBay #Tampa 1...       1  \n",
       "13            #Flood in Bago Myanmar #We arrived Bago       1  \n",
       "14  Damage to school bus on 80 in multi car crash ...       1  \n",
       "15                                     What's up man?       0  \n",
       "16                                      I love fruits       0  \n",
       "17                                   Summer is lovely       0  \n",
       "18                                  My car is so fast       0  \n",
       "19                       What a goooooooaaaaaal!!!!!!       0  \n",
       "20                             this is ridiculous....       0  \n",
       "21                                  London is cool ;)       0  \n",
       "22                                        Love skiing       0  \n",
       "23                              What a wonderful day!       0  \n",
       "24                                           LOOOOOOL       0  \n",
       "25                     No way...I can't eat that shit       0  \n",
       "26                              Was in NYC last week!       0  \n",
       "27                                 Love my girlfriend       0  \n",
       "28                                          Cooool :)       0  \n",
       "29                                 Do you like pasta?       0  \n",
       "30                                           The end!       0  \n",
       "31  @bbcmtd Wholesale Markets ablaze http://t.co/l...       1  \n",
       "32  We always try to bring the heavy. #metal #RT h...       0  \n",
       "33  #AFRICANBAZE: Breaking news:Nigeria flag set a...       1  \n",
       "34                 Crying out for more! Set me ablaze       0  \n",
       "35  On plus side LOOK AT THE SKY LAST NIGHT IT WAS...       0  \n",
       "36  @PhDSquares #mufc they've built so much hype a...       0  \n",
       "37  INEC Office in Abia Set Ablaze - http://t.co/3...       1  \n",
       "38  Barbados #Bridgetown JAMAICA ÛÒ Two cars set ...       1  \n",
       "39                             Ablaze for you Lord :D       0  \n",
       "40  Check these out: http://t.co/rOI2NSmEJJ http:/...       0  \n",
       "41  on the outside you're ablaze and alive\\nbut yo...       0  \n",
       "42  Had an awesome time visiting the CFC head offi...       0  \n",
       "43       SOOOO PUMPED FOR ABLAZE ???? @southridgelife       0  \n",
       "44  I wanted to set Chicago ablaze with my preachi...       0  \n",
       "45  I gained 3 followers in the last week. You? Kn...       0  \n",
       "46  How the West was burned: Thousands of wildfire...       1  \n",
       "47  Building the perfect tracklist to life leave t...       0  \n",
       "48  Check these out: http://t.co/rOI2NSmEJJ http:/...       0  \n",
       "49  First night with retainers in. It's quite weir...       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0cc00d",
   "metadata": {},
   "source": [
    "##### # How many samples of each class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49fb409d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4342\n",
       "1    3271\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5959ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>3796</td>\n",
       "      <td>destruction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>So you have a new weapon that can cause un-ima...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>3185</td>\n",
       "      <td>deluge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5448</th>\n",
       "      <td>7769</td>\n",
       "      <td>police</td>\n",
       "      <td>UK</td>\n",
       "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>191</td>\n",
       "      <td>aftershock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aftershock back to school kick off was great. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6845</th>\n",
       "      <td>9810</td>\n",
       "      <td>trauma</td>\n",
       "      <td>Montgomery County, MD</td>\n",
       "      <td>in response to trauma Children of Addicts deve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id      keyword               location  \\\n",
       "2644  3796  destruction                    NaN   \n",
       "2227  3185       deluge                    NaN   \n",
       "5448  7769       police                     UK   \n",
       "132    191   aftershock                    NaN   \n",
       "6845  9810       trauma  Montgomery County, MD   \n",
       "\n",
       "                                                   text  target  \n",
       "2644  So you have a new weapon that can cause un-ima...       1  \n",
       "2227  The f$&amp;@ing things I do for #GISHWHES Just...       0  \n",
       "5448  DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...       1  \n",
       "132   Aftershock back to school kick off was great. ...       0  \n",
       "6845  in response to trauma Children of Addicts deve...       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_shuffled = train_df.sample(frac=1, random_state=42) # shuffle with random_state=42 for reproducibility\n",
    "train_df_shuffled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c495558",
   "metadata": {},
   "source": [
    "### Let's visualize some random training examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e39d426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "@Tunes_WGG lol. U got wrecked\n",
      "\n",
      "---\n",
      "\n",
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "@twilightfairy flattened frog?\n",
      "\n",
      "---\n",
      "\n",
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "Check out Ameribag Healthy Back Bag Shoulder Cross Body Backpack Khaki Tan Beige Nylon http://t.co/r4k7TyLofJ @eBay\n",
      "\n",
      "---\n",
      "\n",
      "Target: 1 (real disaster)\n",
      "Text:\n",
      "One man fatally shot another wounded on Vermont Street #Buffalo - http://t.co/KakY4mpCO4\n",
      "\n",
      "---\n",
      "\n",
      "Target: 1 (real disaster)\n",
      "Text:\n",
      "Children in Myanmar face a 'double catastrophe' as floods hit the most ... http://t.co/0jFNvAXFph\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random_index = random.randint(0, len(train_df)-5) # create random indexes not higher than the total number of samples\n",
    "for row in train_df_shuffled[[\"text\", \"target\"]][random_index:random_index+5].itertuples():\n",
    "  _, text, target = row\n",
    "  print(f\"Target: {target}\", \"(real disaster)\" if target > 0 else \"(not real disaster)\")\n",
    "  print(f\"Text:\\n{text}\\n\")\n",
    "  print(\"---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d796e083",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Use train_test_split to split training data into training and validation sets\n",
    "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled[\"text\"].to_numpy(),\n",
    "                                                                            train_df_shuffled[\"target\"].to_numpy(),\n",
    "                                                                            test_size=0.1,\n",
    "                                                                            random_state=42) # random state for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73d049b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6851, 6851, 762, 762)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the lengths\n",
    "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0db80770",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import TextVectorization # after TensorFlow 2.6\n",
    "\n",
    "# Before TensorFlow 2.6\n",
    "# from tensorflow.keras.layers.experimental.preprocessing import TextVectorization \n",
    "# Note: in TensorFlow 2.6+, you no longer need \"layers.experimental.preprocessing\"\n",
    "# you can use: \"tf.keras.layers.TextVectorization\"\n",
    "\n",
    "# Use the default TextVectorization variables\n",
    "text_vect = TextVectorization(max_tokens=None, # how many words in the vocabulary (all of the different words in your text)\n",
    "                                    standardize=\"lower_and_strip_punctuation\", # how to process text\n",
    "                                    split=\"whitespace\", # how to split tokens\n",
    "                                    ngrams=None, # create groups of n-words?\n",
    "                                    output_mode=\"int\", # how to map tokens to numbers\n",
    "                                    output_sequence_length=None) # how long should the output sequence of tokens be?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c8fe905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the text vectorizer to the training text\n",
    "text_vect.adapt(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "060ba58a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 6), dtype=int64, numpy=array([[ 74,   9, 232,   4,  13, 182]], dtype=int64)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create sample sentence and tokenize it\n",
    "sample_sentence = \"There is flood in my city\"\n",
    "text_vect([sample_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbb47b20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 12), dtype=int64, numpy=\n",
       "array([[ 74,   9, 232,   4,  13, 182,   7,  46,  22, 884,  10, 148]],\n",
       "      dtype=int64)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create sample sentence and tokenize it\n",
    "sample_sentence = \"There is flood in my city and we are looking for help\"\n",
    "text_vect([sample_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4d6c01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33780fb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find average number of tokens (words) in training Tweets\n",
    "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc9ccbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup text vectorization with custom variables\n",
    "max_vocab_length = 10000 # max number of words to have in our vocabulary (most common words)\n",
    "max_length = 15 # max length our sequences will be (e.g. how many words from a Tweet does our model see?)\n",
    "\n",
    "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
    "                                    output_mode=\"int\",\n",
    "                                    output_sequence_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e8b9cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the text vectorizer to the training text\n",
    "text_vectorizer.adapt(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41a2987e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
       "array([[ 74,   9, 232,   4,  13, 182,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=int64)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create sample sentence and tokenize it\n",
    "sample_sentence = \"There is flood in my city\"\n",
    "text_vectorizer([sample_sentence])\n",
    "# to match the output sequence(so that we can feed those same length vectorized as input)\n",
    "# length it has to generate the remaining 0's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d95e1d70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
       "array([[ 74,   9, 232,   4,  13, 182,   7,  46,  22, 884,  10, 148,   0,\n",
       "          0,   0]], dtype=int64)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create sample sentence and tokenize it\n",
    "sample_sentence = \"There is flood in my city and we are looking for help\"\n",
    "text_vectorizer([sample_sentence])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf45625",
   "metadata": {},
   "source": [
    "### DRAWBACKS of Textvectorization: \n",
    "###           1. creats very huge matrix\n",
    "###           2. results in sparse matrix representation\n",
    "###           3. provides static vector representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1534daf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d63673cb",
   "metadata": {},
   "source": [
    "## Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b74f604",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "embedding = layers.Embedding(input_dim=max_vocab_length, # set input shape\n",
    "                             output_dim=128, # set size of embedding vector\n",
    "                             embeddings_initializer=\"uniform\", # default, intialize randomly\n",
    "                             input_length=max_length, # how long is each input\n",
    "                             name=\"embedding_1\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9ca81fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
       "array([[[ 0.00341318,  0.0385838 ,  0.0482995 , ..., -0.01219044,\n",
       "         -0.03382143, -0.01240605],\n",
       "        [ 0.03907602, -0.00996577,  0.00455119, ..., -0.01726322,\n",
       "         -0.0289162 , -0.02077468],\n",
       "        [ 0.04234011, -0.0494241 ,  0.04350617, ...,  0.00612459,\n",
       "         -0.01769013, -0.02162032],\n",
       "        ...,\n",
       "        [ 0.03057161, -0.03473005,  0.03216963, ...,  0.01682545,\n",
       "         -0.01096151, -0.01314926],\n",
       "        [ 0.03057161, -0.03473005,  0.03216963, ...,  0.01682545,\n",
       "         -0.01096151, -0.01314926],\n",
       "        [ 0.03057161, -0.03473005,  0.03216963, ...,  0.01682545,\n",
       "         -0.01096151, -0.01314926]]], dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sentence = \"There is flood in my city\"\n",
    "sample_embed = embedding(text_vectorizer([sample_sentence]))\n",
    "sample_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c87ab33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
       "array([ 0.00341318,  0.0385838 ,  0.0482995 , -0.04125922,  0.04218273,\n",
       "       -0.03000816,  0.00570237, -0.0283448 , -0.04688933,  0.04971163,\n",
       "        0.01218607, -0.00359259,  0.01555342, -0.04476376, -0.04320319,\n",
       "       -0.00554151,  0.03937198, -0.04493998, -0.03874025,  0.02304268,\n",
       "       -0.02343644, -0.00943673, -0.04366224,  0.02460926, -0.01829016,\n",
       "        0.04970917,  0.04870943, -0.017343  , -0.0312719 ,  0.01673353,\n",
       "       -0.02449809, -0.00525292,  0.02303122,  0.00961993, -0.03076575,\n",
       "       -0.0215794 , -0.04380977, -0.03899655,  0.01624041, -0.04689597,\n",
       "       -0.00665734, -0.01360121,  0.01510251, -0.02594563,  0.00676477,\n",
       "        0.04812134,  0.00848686,  0.03098098,  0.03074406,  0.01697567,\n",
       "        0.01787559, -0.04196798,  0.00872797, -0.04226532, -0.0188435 ,\n",
       "        0.03281286, -0.0385248 ,  0.04298861,  0.03997472, -0.02362732,\n",
       "        0.03123051,  0.04658485, -0.04265263, -0.00023995,  0.00677387,\n",
       "        0.021886  ,  0.0430038 ,  0.02734886,  0.04288976, -0.02430676,\n",
       "        0.04681332, -0.040805  , -0.01974583,  0.02916915,  0.01450035,\n",
       "        0.00029667, -0.00013812, -0.01765461,  0.01838625, -0.02990341,\n",
       "       -0.04162123, -0.03406646, -0.02276774,  0.04867119,  0.03090981,\n",
       "       -0.04079159,  0.02903921, -0.0397475 , -0.01931198,  0.02384086,\n",
       "       -0.0296486 , -0.00588975, -0.03281428,  0.03731623, -0.00065402,\n",
       "        0.03296406, -0.0200389 , -0.01481859, -0.03260807,  0.03805405,\n",
       "       -0.01956055, -0.03749652, -0.00451041,  0.02821045,  0.04930748,\n",
       "       -0.04212498,  0.02316517, -0.03560228,  0.03573493,  0.00421215,\n",
       "       -0.04454484,  0.02826119,  0.02713385, -0.01936864,  0.04597287,\n",
       "       -0.01441509, -0.00130679, -0.01523117,  0.02535066,  0.0495095 ,\n",
       "       -0.00872936,  0.02200756, -0.03642224,  0.03388642, -0.0331636 ,\n",
       "       -0.01219044, -0.03382143, -0.01240605], dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out a single token's embedding\n",
    "sample_embed[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8052954b",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "005489f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LSTM model\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "x = layers.LSTM(64)(x) # return vector for whole sequence\n",
    "x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer on top of output of LSTM cell\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = tf.keras.Model(inputs, outputs, name=\"model_2_LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0f856ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0fba0446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "215/215 [==============================] - 10s 31ms/step - loss: 0.1378 - accuracy: 0.9488 - val_loss: 1.0379 - val_accuracy: 0.7533\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 6s 28ms/step - loss: 0.0558 - accuracy: 0.9753 - val_loss: 1.3628 - val_accuracy: 0.7625\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 6s 28ms/step - loss: 0.0493 - accuracy: 0.9781 - val_loss: 1.3975 - val_accuracy: 0.7625\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 6s 28ms/step - loss: 0.0465 - accuracy: 0.9772 - val_loss: 1.4605 - val_accuracy: 0.7585\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 6s 28ms/step - loss: 0.0470 - accuracy: 0.9783 - val_loss: 1.3389 - val_accuracy: 0.7651\n"
     ]
    }
   ],
   "source": [
    "# Fit model\n",
    "model_history = model.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c1509290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((762, 1),\n",
       " array([[3.2009184e-02],\n",
       "        [7.2615445e-01],\n",
       "        [9.9996895e-01],\n",
       "        [3.5464504e-01],\n",
       "        [1.0961023e-05],\n",
       "        [9.9976331e-01],\n",
       "        [9.9506313e-01],\n",
       "        [9.9999022e-01],\n",
       "        [9.9997157e-01],\n",
       "        [9.7735792e-01]], dtype=float32))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions on the validation dataset\n",
    "model_pred_probs = model.predict(val_sentences)\n",
    "model_pred_probs.shape, model_pred_probs[:10] # view the first 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "266df5c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### We can turn these prediction probabilities into prediction classes by rounding to the nearest integer \n",
    "### (by default, prediction probabilities under 0.5 will go to 0 and those over 0.5 will go to 1).\n",
    "\n",
    "# Round out predictions and reduce to 1-dimensional array\n",
    "model_1_preds = tf.squeeze(tf.round(model_pred_probs))\n",
    "model_1_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ef7fa637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate: accuracy, precision, recall, f1-score\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def calculate_results(y_true, y_pred):\n",
    "    model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
    "    model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
    "    model_results = {\"accuracy\": model_accuracy,\n",
    "                  \"precision\": model_precision,\n",
    "                  \"recall\": model_recall,\n",
    "                  \"f1\": model_f1}\n",
    "    return model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c30ec68c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 76.50918635170603,\n",
       " 'precision': 0.7647692804612646,\n",
       " 'recall': 0.7650918635170604,\n",
       " 'f1': 0.7643429612523406}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_results = calculate_results(val_labels, model_1_preds)\n",
    "model_1_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e5d6bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f28b56c1",
   "metadata": {},
   "source": [
    "### Model 2: GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3101706c",
   "metadata": {},
   "source": [
    "* Another popular and effective RNN component is the GRU or gated recurrent unit.\n",
    "\n",
    "* The GRU cell has similar features to an LSTM cell but has less parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0f1b8152",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "x = layers.GRU(64)(x) # return vector for whole sequence\n",
    "x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer on top of output of LSTM cell\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = tf.keras.Model(inputs, outputs, name=\"model_2_LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "40abcaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile GRU model\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1b93f332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "215/215 [==============================] - 10s 30ms/step - loss: 0.1460 - accuracy: 0.9488 - val_loss: 0.8305 - val_accuracy: 0.7664\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 6s 27ms/step - loss: 0.0530 - accuracy: 0.9755 - val_loss: 1.3703 - val_accuracy: 0.7598\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 6s 27ms/step - loss: 0.0451 - accuracy: 0.9793 - val_loss: 1.3986 - val_accuracy: 0.7651\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 6s 27ms/step - loss: 0.0407 - accuracy: 0.9806 - val_loss: 1.5353 - val_accuracy: 0.7690\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 6s 28ms/step - loss: 0.0386 - accuracy: 0.9815 - val_loss: 1.3256 - val_accuracy: 0.7651\n"
     ]
    }
   ],
   "source": [
    "model_history = model.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "300c77d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((762, 1),\n",
       " array([[1.6377253e-03],\n",
       "        [7.7761751e-01],\n",
       "        [9.9994969e-01],\n",
       "        [2.9974997e-01],\n",
       "        [3.3558783e-05],\n",
       "        [9.9970430e-01],\n",
       "        [9.8614383e-01],\n",
       "        [9.9998409e-01],\n",
       "        [9.9997163e-01],\n",
       "        [9.6405792e-01]], dtype=float32))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions on the validation dataset\n",
    "model_pred_probs = model.predict(val_sentences)\n",
    "model_pred_probs.shape, model_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c250c6ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2_preds = tf.squeeze(tf.round(model_pred_probs))\n",
    "model_2_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "838f1cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 76.50918635170603,\n",
       " 'precision': 0.7666862986020204,\n",
       " 'recall': 0.7650918635170604,\n",
       " 'f1': 0.7628949062414964}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2_results = calculate_results(val_labels, model_2_preds)\n",
    "model_2_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a2e877",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b4dec5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b07172c1",
   "metadata": {},
   "source": [
    "### Model 3: Bidirectonal RNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace3e6c8",
   "metadata": {},
   "source": [
    "* A standard RNN will process a sequence from left to right, where as a bidirectional RNN will process the sequence from left to right and then again from right to left.\n",
    " * In practice, many sequence models often see and improvement in performance when using bidirectional RNN's.\n",
    "\n",
    "* However, this improvement in performance often comes at the cost of longer training times and increased model parameters (since the model goes left to right and right to left, the number of trainable parameters doubles)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e8794e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed and create embedding layer (new embedding layer for each model)\n",
    "tf.random.set_seed(42)\n",
    "from tensorflow.keras import layers\n",
    "model_4_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
    "                                     output_dim=128,\n",
    "                                     embeddings_initializer=\"uniform\",\n",
    "                                     input_length=max_length,\n",
    "                                     name=\"embedding_4\")\n",
    "\n",
    "# Build a Bidirectional RNN in TensorFlow\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = model_4_embedding(x)\n",
    "# x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x) # stacking RNN layers requires return_sequences=True\n",
    "x = layers.Bidirectional(layers.LSTM(64))(x) # bidirectional goes both ways so has double the parameters of a regular LSTM layer\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_4 = tf.keras.Model(inputs, outputs, name=\"model_4_Bidirectional\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "936ed448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile\n",
    "model_4.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5fa15a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "215/215 [==============================] - 11s 33ms/step - loss: 0.5096 - accuracy: 0.7449 - val_loss: 0.4580 - val_accuracy: 0.7822\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 6s 28ms/step - loss: 0.3138 - accuracy: 0.8729 - val_loss: 0.5193 - val_accuracy: 0.7690\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 6s 28ms/step - loss: 0.2154 - accuracy: 0.9177 - val_loss: 0.5680 - val_accuracy: 0.7703\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 6s 28ms/step - loss: 0.1506 - accuracy: 0.9488 - val_loss: 0.6399 - val_accuracy: 0.7769\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 6s 28ms/step - loss: 0.1078 - accuracy: 0.9623 - val_loss: 0.6764 - val_accuracy: 0.7638\n"
     ]
    }
   ],
   "source": [
    "# Fit the model (takes longer because of the bidirectional layers)\n",
    "model_4_history = model_4.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "680c5ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.04676152],\n",
       "       [0.90760857],\n",
       "       [0.9995029 ],\n",
       "       [0.13905993],\n",
       "       [0.00513405],\n",
       "       [0.99759805],\n",
       "       [0.9774306 ],\n",
       "       [0.99959695],\n",
       "       [0.9996257 ],\n",
       "       [0.23314315]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions with bidirectional RNN on the validation data\n",
    "model_4_pred_probs = model_4.predict(val_sentences)\n",
    "model_4_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f290b8c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert prediction probabilities to labels\n",
    "model_4_preds = tf.squeeze(tf.round(model_4_pred_probs))\n",
    "model_4_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f62fe6d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 76.37795275590551,\n",
       " 'precision': 0.7634255198823986,\n",
       " 'recall': 0.7637795275590551,\n",
       " 'f1': 0.7630707606508437}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4_results = calculate_results(val_labels, model_4_preds)\n",
    "model_4_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d7a94f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65a212b0",
   "metadata": {},
   "source": [
    "### Conv1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ac07b00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed and create embedding layer (new embedding layer for each model)\n",
    "tf.random.set_seed(42)\n",
    "from tensorflow.keras import layers\n",
    "model_5_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
    "                                     output_dim=128,\n",
    "                                     embeddings_initializer=\"uniform\",\n",
    "                                     input_length=max_length,\n",
    "                                     name=\"embedding_5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "158c58b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 1-dimensional convolutional layer to model sequences\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = model_5_embedding(x)\n",
    "x = layers.Conv1D(filters=32, kernel_size=5, activation=\"relu\")(x)\n",
    "x = layers.GlobalMaxPool1D()(x)\n",
    "x = layers.Dense(64, activation=\"relu\")(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_5 = tf.keras.Model(inputs, outputs, name=\"model_5_Conv1D\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "36dc5a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile Conv1D model\n",
    "model_5.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0facfd9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "215/215 [==============================] - 7s 28ms/step - loss: 0.0789 - accuracy: 0.9781 - val_loss: 0.6909 - val_accuracy: 0.7717\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 5s 25ms/step - loss: 0.0534 - accuracy: 0.9804 - val_loss: 0.7668 - val_accuracy: 0.7769\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 7s 31ms/step - loss: 0.0462 - accuracy: 0.9823 - val_loss: 0.7805 - val_accuracy: 0.7808\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 6s 28ms/step - loss: 0.0383 - accuracy: 0.9828 - val_loss: 0.8374 - val_accuracy: 0.7808\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 5s 25ms/step - loss: 0.0325 - accuracy: 0.9842 - val_loss: 0.9101 - val_accuracy: 0.7795\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model_5_history = model_5.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5fda909f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5_Conv1D\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (Text  (None, 15)                0         \n",
      " Vectorization)                                                  \n",
      "                                                                 \n",
      " embedding_5 (Embedding)     (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 11, 32)            20512     \n",
      "                                                                 \n",
      " global_max_pooling1d_1 (Gl  (None, 32)                0         \n",
      " obalMaxPooling1D)                                               \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1302689 (4.97 MB)\n",
      "Trainable params: 1302689 (4.97 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9138bed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.14430533],\n",
       "       [0.80381197],\n",
       "       [0.9999866 ],\n",
       "       [0.3958268 ],\n",
       "       [0.00350503],\n",
       "       [0.9998306 ],\n",
       "       [0.8627202 ],\n",
       "       [0.99998087],\n",
       "       [0.9999258 ],\n",
       "       [0.05254416]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions with model_5\n",
    "model_5_pred_probs = model_5.predict(val_sentences)\n",
    "model_5_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e7cece70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert model_5 prediction probabilities to labels\n",
    "model_5_preds = tf.squeeze(tf.round(model_5_pred_probs))\n",
    "model_5_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "15b59c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 77.95275590551181,\n",
       " 'precision': 0.7802422774076316,\n",
       " 'recall': 0.7795275590551181,\n",
       " 'f1': 0.7781078501550943}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5_results = calculate_results(val_labels, model_5_preds)\n",
    "model_5_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e53d1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0d69dc1",
   "metadata": {},
   "source": [
    "### Using Pretrained Embeddings (transfer learning for NLP)\n",
    "\n",
    "* common practice is to leverage pretrained embeddings through transfer learning. This is one of the main benefits of using deep models: being able to take what one (often larger) model has learned (often on a large amount of data) and adjust it for our own use case.\n",
    "* Universal Sentence Encoder:\n",
    "    * Universal Sentence Encoder input is of variable length\n",
    "    * Universal Sentence Encoder outputs a 512 dimensional vector for each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7a5687eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a73e5273",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "\n",
    "sentence_encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
    "                                        input_shape=[], # shape of inputs is variable\n",
    "                                        dtype=tf.string, # data type of inputs coming to the USE layer\n",
    "                                        trainable=False, # keep the pretrained weights (we'll create a feature extractor)\n",
    "                                        name=\"USE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3e92148a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model using the Sequential API\n",
    "model_6 = tf.keras.Sequential([\n",
    "                              sentence_encoder_layer, # take in sentences and then encode them into an embedding\n",
    "                              layers.Dense(64, activation=\"relu\"),\n",
    "                              layers.Dense(32, activation=\"relu\"),\n",
    "                              layers.Dense(1, activation=\"sigmoid\")], name=\"model_6_USE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8af15b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model_6.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7a4b5e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "215/215 [==============================] - 7s 19ms/step - loss: 0.4892 - accuracy: 0.7901 - val_loss: 0.4340 - val_accuracy: 0.8110\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 2s 11ms/step - loss: 0.4033 - accuracy: 0.8216 - val_loss: 0.4213 - val_accuracy: 0.8241\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 2s 11ms/step - loss: 0.3836 - accuracy: 0.8364 - val_loss: 0.4214 - val_accuracy: 0.8150\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 0.3663 - accuracy: 0.8438 - val_loss: 0.4187 - val_accuracy: 0.8176\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 2s 11ms/step - loss: 0.3449 - accuracy: 0.8575 - val_loss: 0.4246 - val_accuracy: 0.8189\n"
     ]
    }
   ],
   "source": [
    "# Train a classifier on top of pretrained embeddings\n",
    "model_6_history = model_6.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b0e6605f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 13ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.10972373],\n",
       "       [0.7657023 ],\n",
       "       [0.9956555 ],\n",
       "       [0.17700359],\n",
       "       [0.5675196 ],\n",
       "       [0.85303515],\n",
       "       [0.9909272 ],\n",
       "       [0.9861459 ],\n",
       "       [0.9693233 ],\n",
       "       [0.0888416 ]], dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions with USE TF Hub model\n",
    "model_6_pred_probs = model_6.predict(val_sentences)\n",
    "model_6_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "58e05fc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert prediction probabilities to labels\n",
    "model_6_preds = tf.squeeze(tf.round(model_6_pred_probs))\n",
    "model_6_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c00a6215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 81.88976377952756,\n",
       " 'precision': 0.8217760859362779,\n",
       " 'recall': 0.8188976377952756,\n",
       " 'f1': 0.8172552520003825}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_6_results = calculate_results(val_labels, model_6_preds)\n",
    "model_6_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7551556",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b11038e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "307ba876",
   "metadata": {},
   "source": [
    "## Comparing the performance of each of our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fb36f0f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LSTM_Model</th>\n",
       "      <td>76.509186</td>\n",
       "      <td>0.764769</td>\n",
       "      <td>0.765092</td>\n",
       "      <td>0.764343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRU_Model</th>\n",
       "      <td>76.509186</td>\n",
       "      <td>0.766686</td>\n",
       "      <td>0.765092</td>\n",
       "      <td>0.762895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bidirectional RNN_Model</th>\n",
       "      <td>76.377953</td>\n",
       "      <td>0.763426</td>\n",
       "      <td>0.763780</td>\n",
       "      <td>0.763071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conv1d</th>\n",
       "      <td>77.952756</td>\n",
       "      <td>0.780242</td>\n",
       "      <td>0.779528</td>\n",
       "      <td>0.778108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USE_Encoder_Model</th>\n",
       "      <td>81.889764</td>\n",
       "      <td>0.821776</td>\n",
       "      <td>0.818898</td>\n",
       "      <td>0.817255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          accuracy  precision    recall        f1\n",
       "LSTM_Model               76.509186   0.764769  0.765092  0.764343\n",
       "GRU_Model                76.509186   0.766686  0.765092  0.762895\n",
       "Bidirectional RNN_Model  76.377953   0.763426  0.763780  0.763071\n",
       "conv1d                   77.952756   0.780242  0.779528  0.778108\n",
       "USE_Encoder_Model        81.889764   0.821776  0.818898  0.817255"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine model results into a DataFrame\n",
    "all_model_results = pd.DataFrame({\"LSTM_Model\": model_1_results,\n",
    "                                  \"GRU_Model\": model_2_results,\n",
    "                                  \"Bidirectional RNN_Model\": model_4_results,\n",
    "                                  \"conv1d\": model_5_results,\n",
    "                                  \"USE_Encoder_Model\": model_6_results})\n",
    "\n",
    "all_model_results = all_model_results.transpose()\n",
    "all_model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ec3d2464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the accuracy to same scale as other metrics\n",
    "all_model_results[\"accuracy\"] = all_model_results[\"accuracy\"]/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "452c8eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7IAAALjCAYAAAAvJTkSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABiOElEQVR4nO3deViU9eL//9cAAm7gjpoI7qK4QouaR9PC1KNZnZO5pkLlweUYlWnmWqlZKXnMrVT0U7lm28ljkruilQhqirlRmIIkpriCwvz+8Od8mwBjELm5h+fjuua6mPe8Z+aFziW+eN/3+7ZYrVarAAAAAAAwCRejAwAAAAAA4AiKLAAAAADAVCiyAAAAAABTocgCAAAAAEyFIgsAAAAAMBWKLAAAAADAVCiyAAAAAABTocgCAAAAAEzFzegA+ZGdna3Tp0+rfPnyslgsRscBAAAAYBCr1aqLFy+qZs2acnFhXa6kMkWRPX36tHx9fY2OAQAAAKCYOHnypGrVqmV0DBjEFEW2fPnykm5+WL28vAxOAwAAAMAo6enp8vX1tXUElEymKLK3Dif28vKiyAIAAADglMMSjoPKAQAAAACmQpEFAAAAAJgKRRYAAAAAYCqmOEcWAAAAAPLLarXqxo0bysrKMjoKHODq6io3N7d8nf9MkQUAAADgNDIzM5WcnKwrV64YHQUFUKZMGdWoUUPu7u63nUeRBQAAAOAUsrOzlZiYKFdXV9WsWVPu7u7sbmwSVqtVmZmZ+u2335SYmKgGDRrIxSXvM2EpsgAAAACcQmZmprKzs+Xr66syZcoYHQcOKl26tEqVKqVffvlFmZmZ8vT0zHMumz0BAAAAcCq3W8lD8Zbfvzv+hgEAAAAApkKRBQAAAACYCufIAgAAAHBq/mO+LtL3+3l69yJ9v5KIFVkAAAAAgJ3r168bHeG2KLIAAAAAYLD169frwQcfVIUKFVS5cmX9/e9/1/Hjx22P//rrr3r66adVqVIllS1bVsHBwfruu+9sj3/55ZcKDg6Wp6enqlSpoieeeML2mMVi0eeff273fhUqVFBUVJQk6eeff5bFYtGqVavUsWNHeXp66qOPPlJaWpr69OmjWrVqqUyZMmrWrJmWL19u9zrZ2dl66623VL9+fXl4eKh27dp68803JUmdOnXS8OHD7eanpaXJw8NDmzZtuqM/L4osAAAAABjs8uXLioiI0A8//KCNGzfKxcVFjz/+uLKzs3Xp0iV16NBBp0+f1pdffql9+/Zp9OjRys7OliR9/fXXeuKJJ9S9e3fFxcVp48aNCg4OdjjDK6+8opEjRyohIUFdunTRtWvXFBQUpP/+97/68ccf9dxzz2nAgAF2BXrs2LF66623NH78eB06dEiffPKJfHx8JElhYWH65JNPlJGRYZv/8ccfq2bNmnrooYfu6M+Lc2QBAAAAwGBPPvmk3f1FixapWrVqOnTokGJiYvTbb7/phx9+UKVKlSRJ9evXt81988039fTTT2vy5Mm2sRYtWjicYdSoUXYruZL00ksv2b4eMWKE1q9fr9WrV+v+++/XxYsX9d5772nOnDl65plnJEn16tXTgw8+aPueRowYoS+++EJPPfWUJGnJkiUaNGiQLBaLw/n+iBVZAAAAADDY8ePH1bdvX9WtW1deXl6qU6eOJCkpKUnx8fFq1aqVrcT+WXx8vDp37nzHGf68ipuVlaU333xTzZs3V+XKlVWuXDlt2LBBSUlJkqSEhARlZGTk+d4eHh7q37+/Fi9ebMu5b98+DRo06I6zsiILAAAAAAbr0aOHfH199cEHH6hmzZrKzs5WYGCgMjMzVbp06ds+968et1gsslqtdmO5beZUtmxZu/vvvvuuZs2apcjISDVr1kxly5bVqFGjlJmZma/3lW4eXtyyZUv9+uuvWrx4sTp37iw/P7+/fN5fYUUWAAAAAAyUlpamhIQEvfbaa+rcubMCAgL0+++/2x5v3ry54uPjde7cuVyf37x5c23cuDHP169ataqSk5Nt948ePaorV678Za7t27frscceU//+/dWiRQvVrVtXR48etT3eoEEDlS5d+rbv3axZMwUHB+uDDz7QJ598oiFDhvzl++YHRRYAAAAADFSxYkVVrlxZCxcu1LFjx7Rp0yZFRETYHu/Tp4+qV6+uXr16aefOnTpx4oQ+/fRT7dq1S5I0ceJELV++XBMnTlRCQoIOHDigGTNm2J7fqVMnzZkzR3v37tWePXs0dOhQlSpV6i9z1a9fX9HR0YqJiVFCQoKef/55paSk2B739PTUK6+8otGjR2vZsmU6fvy4du/erUWLFtm9TlhYmKZPn66srCw9/vjjd/rHJYkiCwAAAACGcnFx0YoVKxQbG6vAwEC98MILevvtt22Pu7u7a8OGDapWrZq6deumZs2aafr06XJ1dZUkdezYUatXr9aXX36pli1bqlOnTnY7C7/77rvy9fXV3/72N/Xt21cvvfSSypQp85e5xo8fr9atW6tLly7q2LGjrUz/ec6LL76oCRMmKCAgQL1791ZqaqrdnD59+sjNzU19+/aVp6fnHfxJ/T8W658Pli6G0tPT5e3trQsXLsjLy8voOAAAAAAMcrtucO3aNSUmJqpOnTqFVphw506ePCl/f3/98MMPat269W3n5vfvkM2eAAAAAACF7vr160pOTtaYMWP0wAMP/GWJdQRFFgAAAHDEJO9CfK0LhfdaQDGzc+dOPfTQQ2rYsKHWrFlTqK9NkQUAAAAAFLqOHTvmuOxPYaHIAgAAwOn5j/m60F7r50I89bLZ0maF92KSDjxzoFBfDyiuKLIAAACAk0hoHFBorxVwOKHQXgsobFx+BwAAAABgKhRZAAAAAICpUGQBAAAAAKZCkQUAAAAAmApFFgAAAABKmC1btshisej8+fOFOreosGsxAAAAAOc2ybuI3+9C0b5fAbRt21bJycny9v7rPxtH5haVAq3Izp07V3Xq1JGnp6eCgoK0ffv2287/+OOP1aJFC5UpU0Y1atTQ4MGDlZaWVqDAAAAAAFCSZWZm3vFruLu7q3r16rJYLIU6t6g4XGRXrlypUaNGady4cYqLi1P79u3VtWtXJSUl5Tp/x44dGjhwoEJDQ3Xw4EGtXr1aP/zwg8LCwu44PAAAAACYXceOHTV8+HANHz5cFSpUUOXKlfXaa6/JarVKkvz9/fXGG29o0KBB8vb21rPPPitJiomJ0d/+9jeVLl1avr6+GjlypC5fvmx73YyMDI0ePVq+vr7y8PBQgwYNtGjRIkk5Dxf+5Zdf1KNHD1WsWFFly5ZV06ZNtW7dulznStKnn36qpk2bysPDQ/7+/nr33Xftvid/f39NnTpVQ4YMUfny5VW7dm0tXLiw0P7MHC6yM2fOVGhoqMLCwhQQEKDIyEj5+vpq3rx5uc7fvXu3/P39NXLkSNWpU0cPPvignn/+ee3Zs+eOwwMAAACAM1i6dKnc3Nz03Xffafbs2Zo1a5Y+/PBD2+Nvv/22AgMDFRsbq/Hjx+vAgQPq0qWLnnjiCe3fv18rV67Ujh07NHz4cNtzBg4cqBUrVmj27NlKSEjQ/PnzVa5cuVzff9iwYcrIyNC2bdt04MABvfXWW3nOjY2N1VNPPaWnn35aBw4c0KRJkzR+/HhFRUXZzXv33XcVHBysuLg4hYeH61//+pcOHz58539YcvAc2czMTMXGxmrMmDF24yEhIYqJicn1OW3bttW4ceO0bt06de3aVampqVqzZo26d++e5/tkZGQoIyPDdj89Pd2RmAAAAABgKr6+vpo1a5YsFosaNWqkAwcOaNasWbbV106dOumll16yzR84cKD69u2rUaNGSZIaNGig2bNnq0OHDpo3b56SkpK0atUqRUdH6+GHH5Yk1a1bN8/3T0pK0pNPPqlmzZr95dyZM2eqc+fOGj9+vCSpYcOGOnTokN5++20NGjTINq9bt24KDw+XJL3yyiuaNWuWtmzZosaNGzv+B/QnDq3Inj17VllZWfLx8bEb9/HxUUpKSq7Padu2rT7++GP17t3bdmx1hQoV9J///CfP95k2bZq8vb1tN19fX0diAgAAAICpPPDAA3bnoLZp00ZHjx5VVlaWJCk4ONhufmxsrKKiolSuXDnbrUuXLsrOzlZiYqLi4+Pl6uqqDh065Ov9R44cqTfeeEPt2rXTxIkTtX///jznJiQkqF27dnZj7dq1s8srSc2bN7d9bbFYVL16daWmpuYrz18p0GZPfz7J12q15nni76FDhzRy5EhNmDBBsbGxWr9+vRITEzV06NA8X3/s2LG6cOGC7Xby5MmCxAQAAAAAp1C2bFm7+9nZ2Xr++ecVHx9vu+3bt09Hjx5VvXr1VLp0aYdePywsTCdOnNCAAQN04MABBQcH57n4mFv/u3U+7x+VKlXK7r7FYlF2drZDufLi0KHFVapUkaura47V19TU1ByrtLdMmzZN7dq108svvyzpZisvW7as2rdvrzfeeEM1atTI8RwPDw95eHg4Eg0AAAAATGv37t057jdo0ECurq65zm/durUOHjyo+vXr5/p4s2bNlJ2dra1bt9oOLf4rvr6+Gjp0qIYOHaqxY8fqgw8+0IgRI3LMa9KkiXbs2GE3FhMTo4YNG+aZt7A5tCLr7u6uoKAgRUdH241HR0erbdu2uT7nypUrcnGxf5tb31xurR0AAAAASpqTJ08qIiJCP/30k5YvX67//Oc/+ve//53n/FdeeUW7du3SsGHDFB8fr6NHj+rLL7+0FU9/f38988wzGjJkiD7//HMlJiZqy5YtWrVqVa6vN2rUKH3zzTdKTEzU3r17tWnTJgUEBOQ698UXX9TGjRv1+uuv68iRI1q6dKnmzJljdw7v3ebQiqwkRUREaMCAAQoODlabNm20cOFCJSUl2Q4VHjt2rE6dOqVly5ZJknr06KFnn31W8+bNU5cuXZScnKxRo0bpvvvuU82aNQv3uwEAAAAAExo4cKCuXr2q++67T66urhoxYoSee+65POc3b95cW7du1bhx49S+fXtZrVbVq1dPvXv3ts2ZN2+eXn31VYWHhystLU21a9fWq6++muvrZWVladiwYfr111/l5eWlRx99VLNmzcp1buvWrbVq1SpNmDBBr7/+umrUqKEpU6bYbfR0t1msBVgWnTt3rmbMmKHk5GQFBgZq1qxZ+tvf/iZJGjRokH7++Wdt2bLFNv8///mP5s+fr8TERFWoUEGdOnXSW2+9pXvuuSdf75eeni5vb29duHBBXl5ejsYFAABACec/5utCe62fPfsW2ms1q1O70F5LklZNu1ForxVwOKHQXqsw3a4bXLt2TYmJiapTp448PT0NSui4jh07qmXLloqMjDQ6iuHy+3fo8IqsJIWHh9u2Uf6zP187SJJGjBiR67HVAAAAAAA4qkC7FgMAAAAAYJQCrcgCAAAAAArHH0/LRP6wIgsAAAAAMBWKLAAAAADAVCiyAAAAAABT4RxZAADgHCZ5F+JrXSi81wIAFDqKLAAAMEzhXtuz0F5KzZY2K7wXk3TgmQOF+noAUNJRZAEAAO6yhMYBhfZaAYcTCu21AMCsOEcWAAAAAEqYSZMmqWXLlrb7gwYNUq9evQzL4yhWZAEAAAA4tcI+XeCvcDrB3ceKLAAAAAAUI5mZmUZHKPYosgAAAABgoI4dO2r48OGKiIhQlSpV9Mgjj+jQoUPq1q2bypUrJx8fHw0YMEBnz561PSc7O1tvvfWW6tevLw8PD9WuXVtvvvmm7fFXXnlFDRs2VJkyZVS3bl2NHz9e169fN+LbuysosgAAAABgsKVLl8rNzU07d+7U9OnT1aFDB7Vs2VJ79uzR+vXrdebMGT311FO2+WPHjtVbb72l8ePH69ChQ/rkk0/k4+Nje7x8+fKKiorSoUOH9N577+mDDz7QrFmzjPjW7grOkQUAAAAAg9WvX18zZsyQJE2YMEGtW7fW1KlTbY8vXrxYvr6+OnLkiGrUqKH33ntPc+bM0TPPPCNJqlevnh588EHb/Ndee832tb+/v1588UWtXLlSo0ePLqLv6O6iyAIl1STvQnytC4X3WgAAACVQcHCw7evY2Fht3rxZ5cqVyzHv+PHjOn/+vDIyMtS5c+c8X2/NmjWKjIzUsWPHdOnSJd24cUNeXl53JbsRKLKFoHAv5t630F6rWZ3ahfZakrRq2o1Cey2ugVcwhftZK7SXKvSdANnpDwAAlDRly5a1fZ2dna0ePXrorbfeyjGvRo0aOnHixG1fa/fu3Xr66ac1efJkdenSRd7e3lqxYoXefffdQs9tFIosgGInoXFAob0WvzQpGH5B5zg+awCAwtK6dWt9+umn8vf3l5tbzsrWoEEDlS5dWhs3blRYWFiOx3fu3Ck/Pz+NGzfONvbLL7/c1cxFjc2eAAAAAKAYGTZsmM6dO6c+ffro+++/14kTJ7RhwwYNGTJEWVlZ8vT01CuvvKLRo0dr2bJlOn78uHbv3q1FixZJunm+bVJSklasWKHjx49r9uzZ+uyzzwz+rgoXRRYAAAAAipGaNWtq586dysrKUpcuXRQYGKh///vf8vb2lovLzQo3fvx4vfjii5owYYICAgLUu3dvpaamSpIee+wxvfDCCxo+fLhatmypmJgYjR8/3shvqdBxaDEAAAAAp1bc99/YsmVLjrEGDRpo7dq1eT7HxcVF48aNszt8+I9mzJhh2wX5llGjRtm+njRpkiZNmmS7HxUV5Uhkw7EiCwAAAAAwFYosAAAAAMBUKLIAAAAAAFOhyAIAAAAATIUiCwAAAAAwFYosAAAAAMBUKLIAAAAAAFOhyAIAAAAATIUiCwAAAAAwFYosAAAAABjMarXqueeeU6VKlWSxWBQfH290pGLNzegAAAAAAHA3JTQOKNL3Czic4PBz1q9fr6ioKG3ZskV169bVkSNH1KNHD8XGxio5OVmfffaZevXqVfhhTYoVWQAAAAAw2PHjx1WjRg21bdtW1atX1+XLl9WiRQvNmTPH6GjFEiuyAAAAAGCgQYMGaenSpZIki8UiPz8//fzzz+ratavByYoviiwAAAAAGOi9995TvXr1tHDhQv3www9ydXU1OlKxR5EFAAAAAAN5e3urfPnycnV1VfXq1Y2OYwqcIwsAAAAAMBWKLAAAAADAVCiyAAAAAABT4RxZAAAAAChmLl26pGPHjtnuJyYmKj4+XpUqVVLt2rUNTFY8UGQBAAAAoJjZs2ePHnroIdv9iIgISdIzzzyjqKgog1IVHxRZAAAAAE4t4HCC0RH+0qhRozRq1Cjb/Y4dO8pqtRoXqJjjHFkAAAAAgKlQZAEAAAAApkKRBQAAAACYCkUWAAAAAGAqFFkAAAAAgKlQZAEAAAA4FXb7Na/8/t1RZAEAAAA4hVKlSkmSrly5YnASFNStv7tbf5d54TqyAAAAAJyCq6urKlSooNTUVElSmTJlZLFYDE6F/LBarbpy5YpSU1NVoUIFubq63nY+RRYAAACA06hevbok2coszKVChQq2v8PbocgCAAAAcBoWi0U1atRQtWrVdP36daPjwAGlSpX6y5XYWwpUZOfOnau3335bycnJatq0qSIjI9W+fftc5w4aNEhLly7NMd6kSRMdPHiwIG8PAAAAALfl6uqa71IE83F4s6eVK1dq1KhRGjdunOLi4tS+fXt17dpVSUlJuc5/7733lJycbLudPHlSlSpV0j//+c87Dg8AAAAAKHkcLrIzZ85UaGiowsLCFBAQoMjISPn6+mrevHm5zvf29lb16tVttz179uj333/X4MGD7zg8AAAAAKDkcajIZmZmKjY2ViEhIXbjISEhiomJyddrLFq0SA8//LD8/PzynJORkaH09HS7GwAAAAAAkoNF9uzZs8rKypKPj4/duI+Pj1JSUv7y+cnJyfrf//6nsLCw286bNm2avL29bTdfX19HYgIAAAAAnJjDhxZLynEtJqvVmq/rM0VFRalChQrq1avXbeeNHTtWFy5csN1OnjxZkJgAAAAAACfk0K7FVapUkaura47V19TU1ByrtH9mtVq1ePFiDRgwQO7u7red6+HhIQ8PD0eiAQAAAABKCIdWZN3d3RUUFKTo6Gi78ejoaLVt2/a2z926dauOHTum0NBQx1MCAAAAAPD/c/g6shERERowYICCg4PVpk0bLVy4UElJSRo6dKikm4cFnzp1SsuWLbN73qJFi3T//fcrMDCwcJIDAAAAAEokh4ts7969lZaWpilTpig5OVmBgYFat26dbRfi5OTkHNeUvXDhgj799FO99957hZMaAAAAAFBiOVxkJSk8PFzh4eG5PhYVFZVjzNvbW1euXCnIWwEAAAAAYKdAuxYDAAAAAGAUiiwAAAAAwFQosgAAAAAAU6HIAgAAAABMhSILAAAAADAViiwAAAAAwFQosgAAAAAAU6HIAgAAAABMhSILAAAAADAViiwAAAAAwFQosgAAAAAAU6HIAgAAAABMhSILAAAAADAViiwAAAAAwFQosgAAAAAAU6HIAgAAAABMhSILAAAAADAViiwAAAAAwFQosgAAAAAAU6HIAgAAAABMhSILAAAAADAViiwAAAAAwFQosgAAAAAAU6HIAgAAAABMhSILAAAAADAViiwAAAAAwFQosgAAAAAAU6HIAgAAAABMhSILAAAAADAViiwAAAAAwFQosgAAAAAAU6HIAgAAAABMhSILAAAAADAViiwAAAAAwFQosgAAAAAAU6HIAgAAAABMhSILAAAAADAViiwAAAAAwFQosgAAAAAAU6HIAgAAAABMhSILAAAAADAViiwAAAAAwFQosgAAAAAAU6HIAgAAAABMhSILAAAAADAViiwAAAAAwFQosgAAAAAAU6HIAgAAAABMhSILAAAAADAViiwAAAAAwFQosgAAAAAAU6HIAgAAAABMpUBFdu7cuapTp448PT0VFBSk7du333Z+RkaGxo0bJz8/P3l4eKhevXpavHhxgQIDAAAAAEo2N0efsHLlSo0aNUpz585Vu3bttGDBAnXt2lWHDh1S7dq1c33OU089pTNnzmjRokWqX7++UlNTdePGjTsODwAAAAAoeRwusjNnzlRoaKjCwsIkSZGRkfrmm280b948TZs2Lcf89evXa+vWrTpx4oQqVaokSfL397+z1AAAAACAEsuhQ4szMzMVGxurkJAQu/GQkBDFxMTk+pwvv/xSwcHBmjFjhu655x41bNhQL730kq5evZrn+2RkZCg9Pd3uBgAAAACA5OCK7NmzZ5WVlSUfHx+7cR8fH6WkpOT6nBMnTmjHjh3y9PTUZ599prNnzyo8PFznzp3L8zzZadOmafLkyY5EAwAAAACUEAXa7Mlisdjdt1qtOcZuyc7OlsVi0ccff6z77rtP3bp108yZMxUVFZXnquzYsWN14cIF2+3kyZMFiQkAAAAAcEIOrchWqVJFrq6uOVZfU1NTc6zS3lKjRg3dc8898vb2to0FBATIarXq119/VYMGDXI8x8PDQx4eHo5EAwAAAACUEA6tyLq7uysoKEjR0dF249HR0Wrbtm2uz2nXrp1Onz6tS5cu2caOHDkiFxcX1apVqwCRAQAAAAAlmcOHFkdEROjDDz/U4sWLlZCQoBdeeEFJSUkaOnSopJuHBQ8cONA2v2/fvqpcubIGDx6sQ4cOadu2bXr55Zc1ZMgQlS5duvC+EwAAAABAieDw5Xd69+6ttLQ0TZkyRcnJyQoMDNS6devk5+cnSUpOTlZSUpJtfrly5RQdHa0RI0YoODhYlStX1lNPPaU33nij8L4LAAAAAECJ4XCRlaTw8HCFh4fn+lhUVFSOscaNG+c4HBkAAAAAgIIo0K7FAAAAAAAYhSILAAAAADAViiwAAAAAwFQosgAAAAAAU6HIAgAAAABMhSILAAAAADAViiwAAAAAwFQosgAAAAAAU6HIAgAAAABMhSILAAAAADAViiwAAAAAwFQosgAAAAAAU6HIAgAAAABMhSILAAAAADAViiwAAAAAwFQosgAAAAAAU6HIAgAAAABMhSILAAAAADAViiwAAAAAwFQosgAAAAAAU6HIAgAAAABMhSILAAAAADAViiwAAAAAwFQosgAAAAAAU6HIAgAAAABMhSILAAAAADAViiwAAAAAwFQosgAAAAAAU6HIAgAAAABMhSILAAAAADAViiwAAAAAwFQosgAAAAAAU6HIAgAAAABMhSILAAAAADAViiwAAAAAwFQosgAAAAAAU6HIAgAAAABMhSILAAAAADAViiwAAAAAwFQosgAAAAAAU6HIAgAAAABMhSILAAAAADAViiwAAAAAwFQosgAAAAAAU6HIAgAAAABMhSILAAAAADAViiwAAAAAwFQosgAAAAAAU6HIAgAAAABMhSILAAAAADAViiwAAAAAwFQKVGTnzp2rOnXqyNPTU0FBQdq+fXuec7ds2SKLxZLjdvjw4QKHBgAAAACUXA4X2ZUrV2rUqFEaN26c4uLi1L59e3Xt2lVJSUm3fd5PP/2k5ORk261BgwYFDg0AAAAAKLkcLrIzZ85UaGiowsLCFBAQoMjISPn6+mrevHm3fV61atVUvXp1283V1bXAoQEAAAAAJZdDRTYzM1OxsbEKCQmxGw8JCVFMTMxtn9uqVSvVqFFDnTt31ubNm287NyMjQ+np6XY3AAAAAAAkB4vs2bNnlZWVJR8fH7txHx8fpaSk5PqcGjVqaOHChfr000+1du1aNWrUSJ07d9a2bdvyfJ9p06bJ29vbdvP19XUkJgAAAADAibkV5EkWi8XuvtVqzTF2S6NGjdSoUSPb/TZt2ujkyZN655139Le//S3X54wdO1YRERG2++np6ZRZAAAAAIAkB1dkq1SpIldX1xyrr6mpqTlWaW/ngQce0NGjR/N83MPDQ15eXnY3AAAAAAAkB4usu7u7goKCFB0dbTceHR2ttm3b5vt14uLiVKNGDUfeGgAAAAAASQU4tDgiIkIDBgxQcHCw2rRpo4ULFyopKUlDhw6VdPOw4FOnTmnZsmWSpMjISPn7+6tp06bKzMzURx99pE8//VSffvpp4X4nAAAAAIASweEi27t3b6WlpWnKlClKTk5WYGCg1q1bJz8/P0lScnKy3TVlMzMz9dJLL+nUqVMqXbq0mjZtqq+//lrdunUrvO8CAAAAAFBiFGizp/DwcIWHh+f6WFRUlN390aNHa/To0QV5GwAAAAAAcnDoHFkAAAAAAIxGkQUAAAAAmApFFgAAAABgKhRZAAAAAICpUGQBAAAAAKZCkQUAAAAAmApFFgAAAABgKhRZAAAAAICpUGQBAAAAAKZCkQUAAAAAmApFFgAAAABgKhRZAAAAAICpUGQBAAAAAKZCkQUAAAAAmApFFgAAAABgKhRZAAAAAICpUGQBAAAAAKZCkQUAAAAAmApFFgAAAABgKhRZAAAAAICpUGQBAAAAAKZCkQUAAAAAmApFFgAAAABgKhRZAAAAAICpUGQBAAAAAKZCkQUAAAAAmApFFgAAAABgKhRZAAAAAICpUGQBAAAAAKZCkQUAAAAAmApFFgAAAABgKhRZAAAAAICpUGQBAAAAAKZCkQUAAAAAmApFFgAAAABgKhRZAAAAAICpUGQBAAAAAKZCkQUAAAAAmApFFgAAAABgKhRZAAAAAICpUGQBAAAAAKZCkQUAAAAAmApFFgAAAABgKhRZAAAAAICpUGQBAAAAAKZCkQUAAAAAmApFFgAAAABgKhRZAAAAAICpUGQBAAAAAKZCkQUAAAAAmApFFgAAAABgKhRZAAAAAICpFKjIzp07V3Xq1JGnp6eCgoK0ffv2fD1v586dcnNzU8uWLQvytgAAAAAAOF5kV65cqVGjRmncuHGKi4tT+/bt1bVrVyUlJd32eRcuXNDAgQPVuXPnAocFAAAAAMDhIjtz5kyFhoYqLCxMAQEBioyMlK+vr+bNm3fb5z3//PPq27ev2rRpU+CwAAAAAAA4VGQzMzMVGxurkJAQu/GQkBDFxMTk+bwlS5bo+PHjmjhxYr7eJyMjQ+np6XY3AAAAAAAkB4vs2bNnlZWVJR8fH7txHx8fpaSk5Pqco0ePasyYMfr444/l5uaWr/eZNm2avL29bTdfX19HYgIAAAAAnFiBNnuyWCx2961Wa44xScrKylLfvn01efJkNWzYMN+vP3bsWF24cMF2O3nyZEFiAgAAAACcUP6WSP9/VapUkaura47V19TU1ByrtJJ08eJF7dmzR3FxcRo+fLgkKTs7W1arVW5ubtqwYYM6deqU43keHh7y8PBwJBoAAAAAoIRwaEXW3d1dQUFBio6OthuPjo5W27Ztc8z38vLSgQMHFB8fb7sNHTpUjRo1Unx8vO6///47Sw8AAAAAKHEcWpGVpIiICA0YMEDBwcFq06aNFi5cqKSkJA0dOlTSzcOCT506pWXLlsnFxUWBgYF2z69WrZo8PT1zjAMAAAAAkB8OF9nevXsrLS1NU6ZMUXJysgIDA7Vu3Tr5+flJkpKTk//ymrIAAAAAABSUw0VWksLDwxUeHp7rY1FRUbd97qRJkzRp0qSCvC0AAAAAAAXbtRgAAAAAAKNQZAEAAAAApkKRBQAAAACYCkUWAAAAAGAqFFkAAAAAgKlQZAEAAAAApkKRBQAAAACYCkUWAAAAAGAqFFkAAAAAgKlQZAEAAAAApkKRBQAAAACYCkUWAAAAAGAqFFkAAAAAgKlQZAEAAAAApkKRBQAAAACYCkUWAAAAAGAqFFkAAAAAgKlQZAEAAAAApkKRBQAAAACYCkUWAAAAAGAqFFkAAAAAgKlQZAEAAAAApkKRBQAAAACYCkUWAAAAAGAqFFkAAAAAgKlQZAEAAAAApkKRBQAAAACYCkUWAAAAAGAqFFkAAAAAgKlQZAEAAAAApkKRBQAAAACYCkUWAAAAAGAqFFkAAAAAgKlQZAEAAAAApkKRBQAAAACYCkUWAAAAAGAqFFkAAAAAgKlQZAEAAAAApkKRBQAAAACYCkUWAAAAAGAqFFkAAAAAgKlQZAEAAAAApkKRBQAAAACYCkUWAAAAAGAqFFkAAAAAgKlQZAEAAAAApkKRBQAAAACYCkUWAAAAAGAqFFkAAAAAgKlQZAEAAAAApkKRBQAAAACYSoGK7Ny5c1WnTh15enoqKChI27dvz3Pujh071K5dO1WuXFmlS5dW48aNNWvWrAIHBgAAAACUbG6OPmHlypUaNWqU5s6dq3bt2mnBggXq2rWrDh06pNq1a+eYX7ZsWQ0fPlzNmzdX2bJltWPHDj3//PMqW7asnnvuuUL5JgAAAAAAJYfDK7IzZ85UaGiowsLCFBAQoMjISPn6+mrevHm5zm/VqpX69Omjpk2byt/fX/3791eXLl1uu4oLAAAAAEBeHCqymZmZio2NVUhIiN14SEiIYmJi8vUacXFxiomJUYcOHfKck5GRofT0dLsbAAAAAACSg0X27NmzysrKko+Pj924j4+PUlJSbvvcWrVqycPDQ8HBwRo2bJjCwsLynDtt2jR5e3vbbr6+vo7EBAAAAAA4sQJt9mSxWOzuW63WHGN/tn37du3Zs0fz589XZGSkli9fnufcsWPH6sKFC7bbyZMnCxITAAAAAOCEHNrsqUqVKnJ1dc2x+pqamppjlfbP6tSpI0lq1qyZzpw5o0mTJqlPnz65zvXw8JCHh4cj0QAAAAAAJYRDK7Lu7u4KCgpSdHS03Xh0dLTatm2b79exWq3KyMhw5K0BAAAAAJBUgMvvREREaMCAAQoODlabNm20cOFCJSUlaejQoZJuHhZ86tQpLVu2TJL0/vvvq3bt2mrcuLGkm9eVfeeddzRixIhC/DYAAAAAACWFw0W2d+/eSktL05QpU5ScnKzAwECtW7dOfn5+kqTk5GQlJSXZ5mdnZ2vs2LFKTEyUm5ub6tWrp+nTp+v5558vvO8CAAAAAFBiOFxkJSk8PFzh4eG5PhYVFWV3f8SIEay+AgAAAAAKTYF2LQYAAAAAwCgUWQAAAACAqVBkAQAAAACmQpEFAAAAAJgKRRYAAAAAYCoUWQAAAACAqVBkAQAAAACmQpEFAAAAAJgKRRYAAAAAYCoUWQAAAACAqVBkAQAAAACmQpEFAAAAAJgKRRYAAAAAYCoUWQAAAACAqVBkAQAAAACmQpEFAAAAAJgKRRYAAAAAYCoUWQAAAACAqVBkAQAAAACmQpEFAAAAAJgKRRYAAAAAYCoUWQAAAACAqVBkAQAAAACmQpEFAAAAAJgKRRYAAAAAYCoUWQAAAACAqVBkAQAAAACmQpEFAAAAAJgKRRYAAAAAYCoUWQAAAACAqVBkAQAAAACmQpEFAAAAAJgKRRYAAAAAYCoUWQAAAACAqVBkAQAAAACmQpEFAAAAAJgKRRYAAAAAYCoUWQAAAACAqVBkAQAAAACmQpEFAAAAAJgKRRYAAAAAYCoUWQAAAACAqVBkAQAAAACmQpEFAAAAAJgKRRYAAAAAYCoUWQAAAACAqVBkAQAAAACmQpEFAAAAAJgKRRYAAAAAYCoUWQAAAACAqVBkAQAAAACmQpEFAAAAAJhKgYrs3LlzVadOHXl6eiooKEjbt2/Pc+7atWv1yCOPqGrVqvLy8lKbNm30zTffFDgwAAAAAKBkc7jIrly5UqNGjdK4ceMUFxen9u3bq2vXrkpKSsp1/rZt2/TII49o3bp1io2N1UMPPaQePXooLi7ujsMDAAAAAEoeh4vszJkzFRoaqrCwMAUEBCgyMlK+vr6aN29ervMjIyM1evRo3XvvvWrQoIGmTp2qBg0a6Kuvvrrj8AAAAACAksehIpuZmanY2FiFhITYjYeEhCgmJiZfr5Gdna2LFy+qUqVKec7JyMhQenq63Q0AAAAAAMnBInv27FllZWXJx8fHbtzHx0cpKSn5eo13331Xly9f1lNPPZXnnGnTpsnb29t28/X1dSQmAAAAAMCJFWizJ4vFYnffarXmGMvN8uXLNWnSJK1cuVLVqlXLc97YsWN14cIF2+3kyZMFiQkAAAAAcEJujkyuUqWKXF1dc6y+pqam5lil/bOVK1cqNDRUq1ev1sMPP3zbuR4eHvLw8HAkGgAAAACghHBoRdbd3V1BQUGKjo62G4+Ojlbbtm3zfN7y5cs1aNAgffLJJ+revXvBkgIAAAAAIAdXZCUpIiJCAwYMUHBwsNq0aaOFCxcqKSlJQ4cOlXTzsOBTp05p2bJlkm6W2IEDB+q9997TAw88YFvNLV26tLy9vQvxWwEAAAAAlAQOF9nevXsrLS1NU6ZMUXJysgIDA7Vu3Tr5+flJkpKTk+2uKbtgwQLduHFDw4YN07Bhw2zjzzzzjKKiou78OwAAAAAAlCgOF1lJCg8PV3h4eK6P/bmcbtmypSBvAQAAAABArgq0azEAAAAAAEahyAIAAAAATIUiCwAAAAAwFYosAAAAAMBUKLIAAAAAAFOhyAIAAAAATIUiCwAAAAAwFYosAAAAAMBUKLIAAAAAAFOhyAIAAAAATIUiCwAAAAAwFYosAAAAAMBUKLIAAAAAAFOhyAIAAAAATIUiCwAAAAAwFYosAAAAAMBUKLIAAAAAAFOhyAIAAAAATIUiCwAAAAAwFYosAAAAAMBUKLIAAAAAAFOhyAIAAAAATIUiCwAAAAAwFYosAAAAAMBUKLIAAAAAAFOhyAIAAAAATIUiCwAAAAAwFYosAAAAAMBUKLIAAAAAAFOhyAIAAAAATIUiCwAAAAAwFYosAAAAAMBUKLIAAAAAAFOhyAIAAAAATIUiCwAAAAAwFYosAAAAAMBUKLIAAAAAAFOhyAIAAAAATIUiCwAAAAAwFYosAAAAAMBUKLIAAAAAAFOhyAIAAAAATIUiCwAAAAAwFYosAAAAAMBUKLIAAAAAAFOhyAIAAAAATIUiCwAAAAAwFYosAAAAAMBUKLIAAAAAAFOhyAIAAAAATIUiCwAAAAAwlQIV2blz56pOnTry9PRUUFCQtm/fnufc5ORk9e3bV40aNZKLi4tGjRpV0KwAAAAAADheZFeuXKlRo0Zp3LhxiouLU/v27dW1a1clJSXlOj8jI0NVq1bVuHHj1KJFizsODAAAAAAo2RwusjNnzlRoaKjCwsIUEBCgyMhI+fr6at68ebnO9/f313vvvaeBAwfK29v7jgMDAAAAAEo2h4psZmamYmNjFRISYjceEhKimJiYQguVkZGh9PR0uxsAAAAAAJKDRfbs2bPKysqSj4+P3biPj49SUlIKLdS0adPk7e1tu/n6+hbaawMAAAAAzK1Amz1ZLBa7+1arNcfYnRg7dqwuXLhgu508ebLQXhsAAAAAYG5ujkyuUqWKXF1dc6y+pqam5lilvRMeHh7y8PAotNcDAAAAADgPh1Zk3d3dFRQUpOjoaLvx6OhotW3btlCDAQAAAACQG4dWZCUpIiJCAwYMUHBwsNq0aaOFCxcqKSlJQ4cOlXTzsOBTp05p2bJltufEx8dLki5duqTffvtN8fHxcnd3V5MmTQrnuwAAAAAAlBgOF9nevXsrLS1NU6ZMUXJysgIDA7Vu3Tr5+flJkpKTk3NcU7ZVq1a2r2NjY/XJJ5/Iz89PP//8852lBwAAAACUOA4XWUkKDw9XeHh4ro9FRUXlGLNarQV5GwAAAAAAcijQrsUAAAAAABiFIgsAAAAAMBWKLAAAAADAVCiyAAAAAABTocgCAAAAAEyFIgsAAAAAMBWKLAAAAADAVCiyAAAAAABTocgCAAAAAEyFIgsAAAAAMBWKLAAAAADAVCiyAAAAAABTocgCAAAAAEyFIgsAAAAAMBWKLAAAAADAVCiyAAAAAABTocgCAAAAAEyFIgsAAAAAMBWKLAAAAADAVCiyAAAAAABTocgCAAAAAEyFIgsAAAAAMBWKLAAAAADAVCiyAAAAAABTocgCAAAAAEyFIgsAAAAAMBWKLAAAAADAVCiyAAAAAABTocgCAAAAAEyFIgsAAAAAMBWKLAAAAADAVCiyAAAAAABTocgCAAAAAEyFIgsAAAAAMBWKLAAAAADAVCiyAAAAAABTocgCAAAAAEyFIgsAAAAAMBWKLAAAAADAVCiyAAAAAABTocgCAAAAAEyFIgsAAAAAMBWKLAAAAADAVCiyAAAAAABTocgCAAAAAEyFIgsAAAAAMBWKLAAAAADAVCiyAAAAAABTocgCAAAAAEyFIgsAAAAAMBWKLAAAAADAVApUZOfOnas6derI09NTQUFB2r59+23nb926VUFBQfL09FTdunU1f/78AoUFAAAAAMDhIrty5UqNGjVK48aNU1xcnNq3b6+uXbsqKSkp1/mJiYnq1q2b2rdvr7i4OL366qsaOXKkPv300zsODwAAAAAoeRwusjNnzlRoaKjCwsIUEBCgyMhI+fr6at68ebnOnz9/vmrXrq3IyEgFBAQoLCxMQ4YM0TvvvHPH4QEAAAAAJY9DRTYzM1OxsbEKCQmxGw8JCVFMTEyuz9m1a1eO+V26dNGePXt0/fp1B+MCAAAAAEo6N0cmnz17VllZWfLx8bEb9/HxUUpKSq7PSUlJyXX+jRs3dPbsWdWoUSPHczIyMpSRkWG7f+HCBUlSenq6I3GLTHbGlUJ7rXSLtdBeK+tqVqG9liRdyiq81yuuf5fFHZ81x/FZKxg+a47js1YwfNYcx2etYPisOa64ftZu5bJaC+/vAebjUJG9xWKx2N23Wq05xv5qfm7jt0ybNk2TJ0/OMe7r6+toVNPxLtRXSyjUV7uvMF/Mu3C/UziOzxqKCp81FBU+aygqfNaKh4sXL8q7mGfE3eNQka1SpYpcXV1zrL6mpqbmWHW9pXr16rnOd3NzU+XKlXN9ztixYxUREWG7n52drXPnzqly5cq3Lcz4f9LT0+Xr66uTJ0/Ky8vL6DhwYnzWUFT4rKGo8FlDUeGzVjBWq1UXL15UzZo1jY4CAzlUZN3d3RUUFKTo6Gg9/vjjtvHo6Gg99thjuT6nTZs2+uqrr+zGNmzYoODgYJUqVSrX53h4eMjDw8NurEKFCo5Exf/Py8uLfxhRJPisoajwWUNR4bOGosJnzXGsxMLhXYsjIiL04YcfavHixUpISNALL7ygpKQkDR06VNLN1dSBAwfa5g8dOlS//PKLIiIilJCQoMWLF2vRokV66aWXCu+7AAAAAACUGA6fI9u7d2+lpaVpypQpSk5OVmBgoNatWyc/Pz9JUnJyst01ZevUqaN169bphRde0Pvvv6+aNWtq9uzZevLJJwvvuwAAAAAAlBgF2uwpPDxc4eHhuT4WFRWVY6xDhw7au3dvQd4KBeTh4aGJEyfmOEQbKGx81lBU+KyhqPBZQ1HhswYUnMXKvtUAAAAAABNx+BxZAAAAAACMRJEFAAAAAJgKRRYAAAAAYCoUWQAAAACAqRRo12IAAO6GL7/8Mt9ze/bseReTAACA4oxdiwHky/79+/M9t3nz5ncxCZyZi0v+DhSyWCzKysq6y2kAAEBxRZEFkC8uLi6yWCzK65+MW49RMACYRURERL7nzpw58y4mAQA4ikOLnQA/iFEUEhMTjY6AEuzatWvy9PQ0OgacTFxcnN392NhYZWVlqVGjRpKkI0eOyNXVVUFBQUbEg5OpWLGiLBZLvuaeO3fuLqcBzI8i6wT+/IM4L/n9xxPIjZ+fn9ERUMJkZWVp6tSpmj9/vs6cOaMjR46obt26Gj9+vPz9/RUaGmp0RJjc5s2bbV/PnDlT5cuX19KlS1WxYkVJ0u+//67Bgwerffv2RkWEE4mMjDQ6AuBUOLQYQIH83//9n+bPn6/ExETt2rVLfn5+ioyMVJ06dfTYY48ZHQ9OYMqUKVq6dKmmTJmiZ599Vj/++KPq1q2rVatWadasWdq1a5fREeFE7rnnHm3YsEFNmza1G//xxx8VEhKi06dPG5QMAJAbLr/jpI4dO6ZvvvlGV69elaQ8z2sECmLevHmKiIhQt27ddP78eds5sRUqVOA3zig0y5Yt08KFC9WvXz+5urraxps3b67Dhw8bmAzOKD09XWfOnMkxnpqaqosXLxqQCM7u+PHjeu2119SnTx+lpqZKktavX6+DBw8anAwwB4qsk0lLS1Pnzp3VsGFDdevWTcnJyZKksLAwvfjiiwang7P4z3/+ow8++EDjxo2zKxjBwcE6cOCAgcngTE6dOqX69evnGM/Oztb169cNSARn9vjjj2vw4MFas2aNfv31V/36669as2aNQkND9cQTTxgdD05m69atatasmb777jutXbtWly5dknTzCgETJ040OB1gDhRZJ/PCCy+oVKlSSkpKUpkyZWzjvXv31vr16w1MBmeSmJioVq1a5Rj38PDQ5cuXDUgEZ9S0aVNt3749x/jq1atz/fwBd2L+/Pnq3r27+vfvLz8/P/n5+alfv37q2rWr5s6da3Q8OJkxY8bojTfeUHR0tNzd3W3jDz30EKdNAPnEZk9OZsOGDfrmm29Uq1Ytu/EGDRrol19+MSgVnE2dOnUUHx+fYwOo//3vf2rSpIlBqeBsJk6cqAEDBujUqVPKzs7W2rVr9dNPP2nZsmX673//a3Q8OJkyZcpo7ty5evvtt3X8+HFZrVbVr19fZcuWNToanNCBAwf0ySef5BivWrWq0tLSDEgEmA9F1slcvnzZbiX2lrNnz8rDw8OARHBGL7/8soYNG6Zr167JarXq+++/1/LlyzVt2jR9+OGHRseDk+jRo4dWrlypqVOnymKxaMKECWrdurW++uorPfLII0bHg5MqW7asmjdvbnQMOLkKFSooOTlZderUsRuPi4vTPffcY1AqwFzYtdjJdO/eXa1bt9brr7+u8uXLa//+/fLz89PTTz+t7OxsrVmzxuiIcBIffPCB3njjDZ08eVLSzR0/J02axCVRADiV48eP69lnn9WmTZuMjgInMnr0aO3atUurV69Ww4YNtXfvXp05c0YDBw7UwIEDOU8WyAeKrJM5dOiQOnbsqKCgIG3atEk9e/bUwYMHde7cOe3cuVP16tUzOiKczNmzZ5Wdna1q1aoZHQUACt2+ffvUunVr2+7sQGG4fv26Bg0apBUrVshqtcrNzU1ZWVnq27evoqKi7DZSBJA7iqwTSklJ0bx58xQbG6vs7Gy1bt1aw4YNU40aNYyOBgC3VbFiRVkslnzNPXfu3F1Og5Jg9uzZt3381KlTeueddyiyuCuOHz+uuLg4ZWdnq1WrVmrQoIHRkQDToMgCyJdWrVrlu2Ds3bv3LqeBs1q6dKnt67S0NL3xxhvq0qWL2rRpI0natWuXvvnmG40fP14vvPCCUTHhRFxcXFSjRg27nWP/KDMzUykpKRRZAChmKLJOYP/+/fmeywYWKKjJkyfbvr527Zrmzp2rJk2a2ArG7t27dfDgQYWHh2vatGlGxYQTefLJJ/XQQw9p+PDhduNz5szRt99+q88//9yYYHAqderU0VtvvaWnnnoq18fj4+MVFBREkcUdi4iIyPfcmTNn3sUkgHOgyDoBFxcXWSwWWa1WuxWzW3+1fxzjBzEKQ1hYmGrUqKHXX3/dbnzixIk6efKkFi9ebFAyOJNy5copPj5e9evXtxs/evSoWrVqpUuXLhmUDM7kH//4h+rVq6e33nor18f37dunVq1aKTs7u4iTwdk89NBDdvdjY2OVlZWlRo0aSZKOHDkiV1dX2z4nAG6Py+84gcTERNvXcXFxeumll/Tyyy/bHYr37rvvasaMGUZFhJNZvXq19uzZk2O8f//+Cg4OpsiiUFSuXFmfffaZXn75Zbvxzz//XJUrVzYoFZzNlClTdOXKlTwfb9Kkid3PWaCgNm/ebPt65syZKl++vJYuXaqKFStKkn7//XcNHjxY7du3NyoiYCqsyDqZ++67T5MmTVK3bt3sxtetW6fx48crNjbWoGRwJtWrV9e0adM0ePBgu/ElS5ZozJgxOnPmjEHJ4EyioqIUGhqqRx991O4Q9vXr1+vDDz/UoEGDjA0IAAV0zz33aMOGDWratKnd+I8//qiQkBCdPn3aoGSAebAi62QOHDiQ4+La0s1zgA4dOmRAIjijUaNG6V//+pdiY2P1wAMPSLpZMBYvXqwJEyYYnA7OYtCgQQoICNDs2bO1du1aWa1WNWnSRDt37tT9999vdDw4mcmTJ6t///5cpg5FIj09XWfOnMlRZFNTU3Xx4kWDUgHmwoqsk2ndurUCAgK0aNEieXp6SpIyMjI0ZMgQJSQksJssCs2qVav03nvvKSEhQZIUEBCgf//733lumAIAxVnz5s118OBB3Xvvverfv7969+6tqlWrGh0LTmrgwIHaunWr3n33XbtfCL/88sv629/+ZreDO4DcUWSdzPfff68ePXooOztbLVq0kHRzowqLxaL//ve/uu+++wxOCAD5l5WVpc8//1wJCQmyWCxq0qSJevbsKVdXV6OjwQkdPHhQH3/8sVasWKFff/1VDz/8sPr3769evXqpTJkyRseDE7ly5YpeeuklLV68WNevX5ckubm5KTQ0VG+//bbKli1rcEKg+KPIOqErV67oo48+0uHDh22H4vXt25d/FFHoYmNj7QpGq1atjI4EJ3Ls2DF169ZNp06dUqNGjWS1WnXkyBH5+vrq66+/5hBQ3FU7d+7UJ598otWrV+vatWtKT083OhKc0OXLl3X8+HFZrVbVr1+f/6sBDqDIAnBYamqqnn76aW3ZskUVKlSQ1WrVhQsX9NBDD2nFihUcjodC0a1bN1mtVn388ceqVKmSJCktLU39+/eXi4uLvv76a4MTwpnFx8fro48+0ooVK5SWlqarV68aHQlO6tdff5XFYtE999xjdBTAVFyMDoDCd/z4cY0YMUIPP/ywHnnkEY0cOVLHjx83OhacyIgRI5Senq6DBw/q3Llz+v333/Xjjz8qPT1dI0eONDoenMTWrVs1Y8YMW4mVbl6SZ/r06dq6dauByeCsEhMT9eabb6pJkyYKDg7W3r17NWnSJKWkpBgdDU4mOztbU6ZMkbe3t/z8/FS7dm1VqFBBr7/+OtcsBvKJXYudzDfffKOePXuqZcuWateunaxWq2JiYtS0aVN99dVXeuSRR4yOCCewfv16ffvttwoICLCNNWnSRO+//75CQkIMTAZn4uHhkevunZcuXZK7u7sBieDM2rRpo++//17NmjXT4MGD1bdvX1bIcNeMGzdOixYt0vTp023/X9u5c6cmTZqka9eu6c033zQ6IlDscWixk2nVqpW6dOmi6dOn242PGTNGGzZsYNdiFIry5ctr+/btatmypd14XFycOnTowLlkKBQDBw7U3r17tWjRIttGdd99952effZZBQUFKSoqytiAcCqvvvqq+vXrl+NyKMDdULNmTc2fP189e/a0G//iiy8UHh6uU6dOGZQMMA+KrJPx9PTUgQMH1KBBA7vxI0eOqHnz5rp27ZpByeBMHnvsMZ0/f17Lly9XzZo1JUmnTp1Sv379VLFiRX322WcGJ4QzOH/+vJ555hl99dVXKlWqlCTpxo0b6tmzp6KiouTt7W1wQgAoGE9PT+3fv18NGza0G//pp5/UsmVLzskG8oFDi51M1apVFR8fn6PIxsfHq1q1agalgrOZM2eOHnvsMfn7+8vX11cWi0VJSUlq1qyZPvroI6PjwUlUqFBBX3zxhY4ePWq3C3v9+vWNjgYnlJWVpaioKG3cuFGpqak5zlPctGmTQcngjFq0aKE5c+Zo9uzZduNz5syxXT4RwO1RZJ3Ms88+q+eee04nTpxQ27ZtZbFYtGPHDr311lt68cUXjY4HJ+Hr66u9e/cqOjrarmA8/PDDRkeDE2rQoEGOX84Bhe3f//63oqKi1L17dwUGBspisRgdCU5sxowZ6t69u7799lu1adNGFotFMTExOnnypNatW2d0PMAUOLTYyVitVkVGRurdd9/V6dOnJd08D+Pll1/WyJEj+cEMoNibMmVKvuZNmDDhLidBSVKlShUtW7ZM3bp1MzoKSojTp0/r/ffft/uFcHh4uO2UHQC3R5F1Yrd2+yxfvrzBSeAsli1blq95AwcOvMtJ4MxcXFxUs2ZNVatWTXn9iLJYLGxeh0JVs2ZNbdmyJcc5iwCA4okiCyDfXFxcVK5cObm5ud22YJw7d66Ik8GZdOvWTZs3b1aXLl00ZMgQde/eXa6urkbHgpN79913deLECc2ZM4ejl3DXJCUl5Wte7dq173ISwPwosk6iU6dO+ZrHZhW4E02bNtWZM2fUv39/DRkyRM2bNzc6EpxUcnKyoqKiFBUVpfT0dA0cOFBDhgxRo0aNjI4GJ/X4449r8+bNqlSpkpo2bWrbKfuWtWvXGpQMzuSPv5S79V/wP/7ixGq1ymKxKCsrq8izAWZDkXUSLi4u8vPzU/fu3XP88P2jWbNmFWEqOKPvvvtOixcv1sqVK1W/fn2FhoaqX79+8vLyMjoanNS2bdu0ZMkSffrpp2rWrJm+/fZblS5d2uhYcDKDBw++7eNLliwpoiRwZm5ubqpVq5YGDRqkHj16yM0t931X2bkY+GsUWScxY8YMRUVFKS0tTf369dOQIUMUGBhodCw4satXr2r16tVasmSJvv/+e/Xq1UuLFy+Wh4eH0dHgZG591t5//30dOHBAKSkp/OIEgCmlpKRo6dKlioqK0u+//67+/fsrNDRUAQEBRkcDTIci62R27dqlxYsXa9WqVWrUqJGGDBmivn378p8+3DXbtm3TxIkTtW3bNp09e1YVK1Y0OhKcxB//PWvYsKEGDx6svn37qkKFCkZHgxP77bff9NNPP8lisahhw4aqWrWq0ZHgpHbs2KElS5Zo9erVatKkiUJDQxUaGioXFxejowGmQJF1UleuXLGtYBw6dEinT5+mzKLQnDp1SkuXLtWSJUt0+fJl2zmzjRs3NjoanMCMGTO0ZMkSuyNMmjVrZnQsOLnLly9rxIgRWrZsmbKzsyXdPJ9x4MCB+s9//qMyZcoYnBDO6syZM+rTp4+2bt2q3377TZUqVTI6EmAKFFkntWPHDi1evFirV69W06ZNtXnzZs4pwx1btWqVlixZoq1bt6pLly4aPHgwO8qi0Lm4uKh27dr6+9//Lnd39zznzZw5swhTwdk9//zz+vbbbzVnzhy1a9dO0s2fpSNHjtQjjzyiefPmGZwQziYmJsb2f7VbR9E999xzrMgC+USRdSKnT5+22+Xz1ipZkyZNjI4GJ3GrYPTr108+Pj55zhs5cmQRpoKz6dix419e/sRisbALOwpVlSpVtGbNGnXs2NFufPPmzXrqqaf022+/GRMMTiU5OVnLli3TkiVL9Pvvv6tfv34KDQ1V06ZNjY4GmA5F1kncuu5iSEiI7bqLee2EBxSUv79/vgrGiRMniigRABSOMmXKKDY2NsemOwcPHtR9992ny5cvG5QMzsTd3V01a9bUM888o549e+Z5pQkubwf8NYqsk3BxcVGNGjVUrVq12xaNvXv3FmEqALj7vLy8FB8fr7p16xodBSbWuXNnVa5cWcuWLZOnp6ekmztmP/PMMzp37py+/fZbgxPCGfzxsOFb/1/783/FuY4skD8s2TmJiRMnGh0ByKFZs2Zat26dfH19jY4CJ8bvY1EYIiMj1bVrV9WqVUstWrSQxWJRfHy8PDw8tGHDBqPjwUkkJiYaHQFwGqzIllA7d+5UcHAw1/zEXVW+fHnt27ePlTLcVXzOUFiuXr2qjz76SIcPH5bValWTJk3Ur18/NkuEYcLDwzVlyhRVqVLF6ChAsUORLaE4FA9FgYKBosDnDIVh2rRp8vHx0ZAhQ+zGFy9erN9++02vvPKKQclQkvH/NSBv7O9dQvH7CwAA/p8FCxbkei3spk2bav78+QYkAvj/GnA7FFkAgKn91U7aQH6kpKSoRo0aOcarVq2q5ORkAxIBAG6HIgsAMDVWLFAYfH19tXPnzhzjO3fuVM2aNQ1IBAC4HXYtBgCY2v/+9z/dc889RseAyYWFhWnUqFG6fv26OnXqJEnauHGjRo8erRdffNHgdACAP6PIllAcioeisGDBAvn4+BgdAyYzZcqUfM2bMGGCJOnBBx+8m3FQQowePVrnzp1TeHi4MjMzJUmenp565ZVXNHbsWIPTAQD+jF2LSyh2+URB5FUwvL291ahRI4WEhNhd7B0oiFatWuX5mMVi0U8//aRr164pKyurCFOhpLh06ZISEhJUunRpNWjQgMvUodDduHFDb775poYMGfKX11n/17/+pddff53L7wC5oMgCyLe8Csb58+d16tQpNW3aVN98842qVatWxMlQEsTHx2vMmDHatGmThgwZwk6yAEyrXLly+vHHH+Xv7290FMC0KLJO4tb5PH9l06ZNdzkJSqrk5GT17dtX9erV04cffmh0HDiRxMREjR8/XitXrtQTTzyhN954Qw0aNDA6FgAUWK9evdSrVy8NGjTI6CiAaXGOrJPYsmWL/Pz81L17d5UqVcroOCiBatSooTfeeEMDBgwwOgqcxNmzZzV58mQtXLhQDz74oGJiYnTvvfcaHQsA7ljXrl01duxY/fjjjwoKClLZsmXtHu/Zs6dByQDzYEXWScyYMUNRUVFKS0tTv379NGTIEAUGBhodCyXMzz//rMDAQF26dMnoKDCxy5cv65133tHMmTNVv359TZs2TSEhIUbHAoBCc7v9JCwWC3sAAPlAkXUyu3bt0uLFi7Vq1So1atRIQ4YMUd++feXl5WV0NJQAX3zxhcaNG6cff/zR6CgwserVq+vixYsaMWKE+vTpk+cu682bNy/iZAAAoLigyDqpK1euaPXq1Xr//fd16NAhnT59mjKLO5aenp7r+IULF/TDDz/oxRdfVFhYmMaNG1fEyeBM/rhSYbFY9McfU7fus2IBwFlcu3ZNnp6eRscATIdzZJ3U3r17tXXrViUkJCgwMJDzZlEoKlSokOfqmMVi0fPPP6/Ro0cXcSo4m8TERKMjAMBdlZWVpalTp2r+/Pk6c+aMjhw5orp162r8+PHy9/dXaGio0RGBYo8i60ROnz6tqKgoRUVFKT09Xf3799d3332nJk2aGB0NTmLz5s25jnt5ealBgwYqV65cESeCM/Lz8zM6AgDcVW+++aaWLl2qGTNm6Nlnn7WNN2vWTLNmzaLIAvnAocVOolu3btq8ebNCQkI0ZMgQde/eXW5u/J4CgPkkJSXla17t2rXvchIAuDvq16+vBQsWqHPnzipfvrz27dununXr6vDhw2rTpo1+//13oyMCxR5F1km4uLioRo0aqlatWp6Hfko3DzkG7pa1a9dq0qRJ2r9/v9FRYGIuLi65/jt269xY6eah7Ddu3CjqaABQKEqXLq3Dhw/Lz8/PrsgeOnRI9913H7v/A/nAkp2TmDhxotERUEJ88MEH2rBhg0qVKqV///vfuv/++7Vp0ya9+OKL+umnn7iOLO5YXFxcruNWq1UrVqzQ7NmzOYwdgKk1bdpU27dvz3EqxerVq9WqVSuDUgHmQpF1EoMHD1atWrVue10y4E698847evXVV9W8eXMlJCTYLrczc+ZMjRgxQsOGDVOVKlWMjgmTa9GiRY6xb7/9VmPGjNGRI0c0evRovfTSSwYkA4DCMXHiRA0YMECnTp1Sdna21q5dq59++knLli3Tf//7X6PjAabAocVOwtXVVcnJyapWrZrRUeDEAgIC9PLLL2vIkCHasmWLOnXqpE6dOmnNmjWqUKGC0fHghGJjYzVmzBht375dYWFhmjBhAv/OAXAK33zzjaZOnarY2FhlZ2erdevWmjBhgkJCQoyOBpgCRdZJuLi4KCUlhf/g4a4qU6aMDh8+bNtkx8PDQ9u2bdP9999vcDI4m2PHjmncuHH69NNP9dRTT+mNN95Q3bp1jY4FAACKCY5DBZBvf75ou7u7u6pWrWpgIjij8PBwNW3aVBcuXNCePXv0ySefUGIBAIAdzpF1Ih9++OFfboAycuTIIkoDZ/XHz9mNGzcUFRWV47xYPme4E/Pnz5enp6dSU1M1ZMiQPOexCzsAM6lYseJtryzxR+fOnbvLaQDz49BiJ+Hi4qJatWrJ1dU1zzkWi0UnTpwowlRwNv7+/n/5Q5jPGe7U5MmT8zWP3doBmMnSpUttX6elpemNN95Qly5d1KZNG0nSrl279M0332j8+PF64YUXjIoJmAZF1klwjiwAAIA5PPnkk3rooYc0fPhwu/E5c+bo22+/1eeff25MMMBEKLJOgl2LURSuXbumb7/9Vn//+98lSWPHjlVGRobtcTc3N02ZMsXuPFqgsF27dk1z5szhEjwATKtcuXKKj49X/fr17caPHj2qVq1a6dKlSwYlA8yDzZ6cBL+PQFFYunSpFixYYLs/Z84cxcTEKC4uTnFxcfq///s/zZ0718CEcBZnz57V119/rQ0bNigrK0uSdP36db333nvy9/fX9OnTDU4IAAVXuXJlffbZZznGP//8c1WuXNmARID5sNmTk5g4ceJfbvQE3KmPP/44x3k7f9xR9qOPPtL777+viIgII+LBScTExKh79+66cOGCLBaLgoODtWTJEvXq1UvZ2dl67bXXbrsJFAAUd5MnT1ZoaKi2bNliO0d29+7dWr9+vT788EOD0wHmwKHFTuLcuXO6cuWKatWqZRs7ePCg3nnnHV2+fFm9evVS3759DUwIZ1C9enVt3LhRTZs2lSRVrVpVP/zwg/z9/SVJR44c0b333qsLFy4YmBJm17lzZ1WtWlWvvfaaFi9erMjISPn7+2vSpEkaMGBAvnf9BIDi7LvvvtPs2bOVkJAgq9WqJk2aaOTIkVybHcgniqyT6NOnj2rUqKGZM2dKklJTU9W4cWPVrFlT9erV0//+9z8tWrRIAwYMMDgpzKx06dKKj49Xo0aNcn388OHDatmypa5du1bEyeBMqlSpoq1bt6pp06a6cuWKypcvrxUrVuif//yn0dEAAEAxwaHFTmL37t1asmSJ7f6yZctUqVIlxcfHy83NTe+8847ef/99iizuSK1atfTjjz/mWWT3799vd1QAUBDnzp1T1apVJUllypRRmTJl1KpVK4NTAUDhysrK0ueff66EhARZLBY1adJEPXv2vO2lFAH8PxRZJ5GSkqI6derY7m/atEmPP/643Nxu/hX37NlT06ZNMyoenES3bt00YcIEde/ePcfOxFevXtXkyZPVvXt3g9LBWVgsFl28eFGenp6yWq2yWCy6cuWK0tPT7eZ5eXkZlBAA7syxY8fUrVs3nTp1So0aNZLVatWRI0fk6+urr7/+WvXq1TM6IlDscWixk/Dx8dGGDRvUokULSTcPzVuwYIGefPJJSWznjsJx5swZtWzZUu7u7ho+fLgaNmwoi8Wiw4cPa86cObpx44bi4uLk4+NjdFSYmIuLi915sLfK7J/v39rNGADMplu3brJarfr4449VqVIlSVJaWpr69+8vFxcXff311wYnBIo/VmSdxH333afZs2frgw8+0Nq1a3Xx4kV16tTJ9vit3/IBd8LHx0cxMTH617/+pTFjxtgu+2SxWPTII49o7ty5lFjcsc2bNxsdAQDuqq1bt2r37t22EivdvCTP9OnT1a5dOwOTAeZBkXUSr7/+uh5++GF99NFHunHjhl599VVVrFjR9viKFSvUoUMHAxPCWdSpU0fr16/XuXPndOzYMUlS/fr17X4YA3eCf6sAODsPDw9dvHgxx/ilS5fk7u5uQCLAfCiyTqJly5ZKSEhQTEyMqlevnmPr9pCQEG3cuNGgdHBGlSpV0n333Wd0DAAATOfvf/+7nnvuOS1atMj2s/S7777T0KFD1bNnT4PTAebAObIlxL59+9S6dWvOKQMAADDY+fPn9cwzz+irr75SqVKlJEk3btxQz549FRUVJW9vb4MTAsUfK7IAAABAEapQoYK++OILHTt2TAkJCbJarWrSpInq169vdDTANCiyAAAAgAHq169PeQUKyMXoAAAAAEBJ8o9//EPTp0/PMf7222/rn//8pwGJAPPhHFkn8cQTT9z28fPnz2vr1q2cIwugWPurf8v+aO3atXcxCQDcPVWrVtWmTZvUrFkzu/EDBw7o4Ycf1pkzZwxKBpgHhxY7ib/aFMDb21sDBw4sojQAUDBscAKgJMjrMjulSpVSenq6AYkA82FFFgAAAChC9957r3r06KEJEybYjU+aNElfffWVYmNjDUoGmAcrsgAAAEARGj9+vJ588kkdP35cnTp1kiRt3LhRy5cv1+rVqw1OB5gDK7IAgGJrzZo1WrVqlZKSkpSZmWn32N69ew1KBQB37uuvv9bUqVMVHx+v0qVLq3nz5po4caI6dOhgdDTAFNi1GABQLM2ePVuDBw9WtWrVFBcXp/vuu0+VK1fWiRMn1LVrV6PjAcAd6d69u3bu3KnLly/r7Nmz2rRpEyUWcAArsgCAYqlx48aaOHGi+vTpo/Lly2vfvn2qW7euJkyYoHPnzmnOnDlGRwSAO5KZmanU1FRlZ2fbjdeuXdugRIB5UGQBAMVSmTJllJCQID8/P1WrVk3R0dFq0aKFjh49qgceeEBpaWlGRwSAAjl69KiGDBmimJgYu3Gr1SqLxcLlEoF8YLMnAECxVL16daWlpcnPz09+fn7avXu3WrRoocTERPE7WABmNmjQILm5uem///2vatSoIYvFYnQkwHQosgCAYqlTp0766quv1Lp1a4WGhuqFF17QmjVrtGfPHj3xxBNGxwOAAouPj1dsbKwaN25sdBTAtDi0GABQLGVnZys7O1tubjd/57pq1Srt2LFD9evX19ChQ+Xu7m5wQgAomHvvvVezZs3Sgw8+aHQUwLQosgAAAEAR2rRpk1577TVNnTpVzZo1U6lSpewe9/LyMigZYB4UWQBAsXX+/Hl9//33ue7qOXDgQINSAcCdcXG5eQXMP58by2ZPQP5RZAEAxdJXX32lfv366fLlyypfvrzdf/gsFovOnTtnYDoAKLitW7fe9nGuJwv8NYosAKBYatiwobp166apU6eqTJkyRscBAADFiIvRAQAAyM2pU6c0cuRISiwApzFjxgxdvXrVdn/btm3KyMiw3b948aLCw8ONiAaYDiuyAIBi6YknntDTTz+tp556yugoAFAoXF1dlZycrGrVqkm6ualTfHy86tatK0k6c+aMatasyTmyQD5wHVkAQLHUvXt3vfzyyzp06FCuu3r27NnToGQAUDB/Xj9iPQkoOFZkAQDF0q1dPXPDrp4AzMjFxUUpKSm2Fdny5ctr3759rMgCBcCKLACgWPrz5XYAAABuocgCAAAAReTDDz9UuXLlJEk3btxQVFSUqlSpIunmZk8A8odDiwEAxdbWrVv1zjvvKCEhQRaLRQEBAXr55ZfVvn17o6MBgMP8/f3tromdl8TExCJIA5gbRRYAUCx99NFHGjx4sJ544gm1a9dOVqtVMTEx+uyzzxQVFaW+ffsaHREAABiEIgsAKJYCAgL03HPP6YUXXrAbnzlzpj744AMlJCQYlAwAikazZs20bt06+fr6Gh0FKHby3hISAAADnThxQj169Mgx3rNnTw67A1Ai/Pzzz7p+/brRMYBiiSILACiWfH19tXHjxhzjGzduZHUCAIASjl2LAQDF0osvvqiRI0cqPj5ebdu2lcVi0Y4dOxQVFaX33nvP6HgAAMBAFFkAQLH0r3/9S9WrV9e7776rVatWSbp53uzKlSv12GOPGZwOAAAYic2eAAAAgGKofPny2rdvn+rWrWt0FKDY4RxZAAAAAICpcGgxAKDYqFSpko4cOaIqVaqoYsWKslgsec49d+5cESYDgKK3YMEC+fj4GB0DKJYosgCAYmPWrFkqX7687evbFVkAMJtu3bpp+fLl8vb2liS9+eabGjZsmCpUqCBJSktLU/v27XXo0CFJUt++fY2KChR7nCMLAAAAFAFXV1clJyerWrVqkiQvLy/Fx8fbzoE9c+aMatasqaysLCNjAqbAObIAgGLJ1dVVqampOcbT0tLk6upqQCIAuDN/Xj9iPQkoOIosAKBYyus/eBkZGXJ3dy/iNAAAoDjhHFkAQLEye/ZsSZLFYtGHH36ocuXK2R7LysrStm3b1LhxY6PiAUCBWSyWHOf+sxcAUDAUWQBAsTJr1ixJN1dk58+fb3cYsbu7u/z9/TV//nyj4gFAgVmtVg0aNEgeHh6SpGvXrmno0KEqW7aspJtHnADIHzZ7AgAUSw899JDWrl2rihUrGh0FAArF4MGD8zVvyZIldzkJYH4UWQAAAACAqbDZEwCgWPrHP/6h6dOn5xh/++239c9//tOARABwd/zyyy86dOiQsrOzjY4CmAZFFgBQLG3dulXdu3fPMf7oo49q27ZtBiQCgDuzdOlSRUZG2o0999xzqlu3rpo1a6bAwECdPHnSmHCAyVBkAQDF0qVLl3K9zE6pUqWUnp5uQCIAuDPz58+Xt7e37f769eu1ZMkSLVu2TD/88IMqVKigyZMnG5gQMA+KLACgWAoMDNTKlStzjK9YsUJNmjQxIBEA3JkjR44oODjYdv+LL75Qz5491a9fP7Vu3VpTp07Vxo0bDUwImAeX3wEAFEvjx4/Xk08+qePHj6tTp06SpI0bN2r58uVavXq1wekAwHFXr16Vl5eX7X5MTIyGDBliu1+3bl2lpKQYEQ0wHYosAKBY6tmzpz7//HNNnTpVa9asUenSpdW8eXN9++236tChg9HxAMBhfn5+io2NlZ+fn86ePauDBw/qwQcftD2ekpJid+gxgLxRZAEAxVb37t1z3fAJAMxo4MCBGjZsmA4ePKhNmzapcePGCgoKsj0eExOjwMBAAxMC5kGRBQAUW+fPn9eaNWt04sQJvfTSS6pUqZL27t0rHx8f3XPPPUbHAwCHvPLKK7py5YrWrl2r6tWr5zhNYufOnerTp49B6QBzsVitVqvRIQAA+LP9+/fr4Ycflre3t37++Wf99NNPqlu3rsaPH69ffvlFy5YtMzoiAAAwCLsWAwCKpYiICA0aNEhHjx6Vp6enbbxr165cRxaAKbm4uMjV1TXHrWLFinrggQe0du1aoyMCpsGhxQCAYumHH37QggULcozfc8897OoJwJQ+++yzXMfPnz+v77//Xv3799fSpUv1z3/+s4iTAeZDkQUAFEuenp5KT0/PMf7TTz+patWqBiQCgDvz2GOP5fnYM888oyZNmuidd96hyAL5wKHFAIBi6bHHHtOUKVN0/fp1SZLFYlFSUpLGjBmjJ5980uB0AFD4QkJCdOTIEaNjAKZAkQUAFEvvvPOOfvvtN1WrVk1Xr15Vhw4dVL9+fZUvX15vvvmm0fEAoNBdvXrVbk8AAHlj12IAQLG2adMm7d27V9nZ2WrdurUefvhhoyMBwF0xYsQIHT9+XOvWrTM6ClDsUWQBAMXOjRs35Onpqfj4eAUGBhodBwAKRURERK7jFy5c0J49e3T8+HFt375drVq1KuJkgPmw2RMAoNhxc3OTn5+fsrKyjI4CAIUmLi4u13EvLy89+uijCg8Pl5+fXxGnAsyJFVkAQLG0ZMkSrV69Wh999JEqVapkdBwAAFCMUGQBAMVSq1atdOzYMV2/fl1+fn4qW7as3eN79+41KBkAADAahxYDAIqlXr16GR0BAAAUU6zIAgAAAABMhevIAgAAAABMhUOLAQDFRqVKlXTkyBFVqVJFFStWlMViyXPuuXPnijAZAAAoTiiyAIBiY9asWSpfvrwkKTIy0tgwAACg2OIcWQAAAACAqbAiCwAoNtLT0/M918vL6y4mAQAAxRkrsgCAYsPFxeW258X+UVZW1l1OAwAAiitWZAEAxcbmzZttX//8888aM2aMBg0apDZt2kiSdu3apaVLl2ratGlGRQQAAMUAK7IAgGKpc+fOCgsLU58+fezGP/nkEy1cuFBbtmwxJhgAADAcRRYAUCyVKVNG+/btU4MGDezGjxw5opYtW+rKlSsGJQMAAEZzMToAAAC58fX11fz583OML1iwQL6+vgYkAgAAxQXnyAIAiqVZs2bpySef1DfffKMHHnhAkrR7924dP35cn376qcHpAACAkTi0GABQbJ08eVLz5s3T4cOHZbVa1aRJEw0dOpQVWQAASjiKLAAAAADAVDi0GABQbOzfv1+BgYFycXHR/v37bzu3efPmRZQKAAAUN6zIAgCKDRcXF6WkpKhatWpycXGRxWJRbj+mLBaLsrKyDEgIAACKA1ZkAQDFRmJioqpWrWr7GgAAIDesyAIAAAAATIUVWQBAsZSWlqbKlStLurl78QcffKCrV6+qZ8+eat++vcHpAACAkViRBQAUKwcOHFCPHj108uRJNWjQQCtWrNCjjz6qy5cvy8XFRZcvX9aaNWvUq1cvo6MCAACDuBgdAACAPxo9erSaNWumrVu3qmPHjvr73/+ubt266cKFC/r999/1/PPPa/r06UbHBAAABmJFFgBQrFSpUkWbNm1S8+bNdenSJXl5een7779XcHCwJOnw4cN64IEHdP78eWODAgAAw7AiCwAoVs6dO6fq1atLksqVK6eyZcuqUqVKtscrVqyoixcvGhUPAAAUAxRZAECxY7FYbnsfAACUbOxaDAAodgYNGiQPDw9J0rVr1zR06FCVLVtWkpSRkWFkNAAAUAxwjiwAoFgZPHhwvuYtWbLkLicBAADFFUUWAAAAAGAqnCMLAAAAADAViiwAAAAAwFQosgAAAAAAU6HIAgAAAABMhSILAAAAADAViiwAAAAAwFQosgAAAAAAU6HIAgAAAABMhSILAAAAADCV/w8PlLh+GLUSmAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot and compare all of the model results\n",
    "all_model_results.plot(kind=\"bar\", figsize=(10, 7)).legend(bbox_to_anchor=(1.0, 1.0));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf7506d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc517457",
   "metadata": {},
   "source": [
    "### Saving and loading a trained model\n",
    "\n",
    "* There are two main ways of saving a model in TensorFlow:\n",
    "\n",
    "    * The HDF5 format.\n",
    "    * The SavedModel format (default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878cb16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save TF Hub Sentence Encoder model to HDF5 format\n",
    "model_6.save(\"model_6.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88cb6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model_6 = tf.keras.models.load_model(\"model_6.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c74448c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How does our loaded model perform?\n",
    "loaded_model_6.evaluate(val_sentences, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed0c0c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf62e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save TF Hub Sentence Encoder model to SavedModel format (default)\n",
    "model_6.save(\"model_6_SavedModel_format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b240de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TF Hub Sentence Encoder SavedModel\n",
    "loaded_model_6_SavedModel = tf.keras.models.load_model(\"model_6_SavedModel_format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837bb8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate loaded SavedModel format\n",
    "loaded_model_6_SavedModel.evaluate(val_sentences, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd151ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb6b824",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
